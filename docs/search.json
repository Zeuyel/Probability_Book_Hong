[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Preface\nThis is a book for reviewing the class Probability Theory.\nClass Matetial: the Professor Hong Yongmiao Class\nBook: „ÄäProbability and Statistics for Economists„ÄãÔºà Yongmiao Hong, World Scientific, 2017Ôºâ\nVideo: Bilibili"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1¬† Introduce",
    "section": "",
    "text": "2 General methodology of modern ecnomic research\nModern economy is essentially built by upon the following three fundamental axioms:\nSo we establish the econometrics to infer the probability laws from the observed data that reflect the stochastic economic system, and then use the inferred probability laws for economic application e.g.¬†to make predictions and conduct policy analysis."
  },
  {
    "objectID": "intro.html#data-collection",
    "href": "intro.html#data-collection",
    "title": "1¬† Introduce",
    "section": "2.1 Data collection",
    "text": "2.1 Data collection\n\nsurvey\nfield studies\nexperimental economics\nBig data\n\nIn most time,we get so-called stylized facts by summarizing from observed economic data.\nüå∞ÔºöEngel Curve,Phillips Curve,Okun‚Äôs Law,volatility clustering in finance,etc.\nSo the empirical research is the first step of economic research which is so-called economical intuition.But for more further understanding,we need to build a model to explain the stylized facts by using the statistic tools."
  },
  {
    "objectID": "intro.html#development-of-economic-theories-and-models",
    "href": "intro.html#development-of-economic-theories-and-models",
    "title": "1¬† Introduce",
    "section": "2.2 Development of economic theories and models",
    "text": "2.2 Development of economic theories and models\nWith the emprical stylized facts,we can build a model to explain the facts and make predictions.This process is called mathematical modeling of economic theroy.\nüå∞: An example is the Euler equation for rational expectations in macroeconomics.\nMoreover, the objective of economic modeling is not merely to explain the stylized facts but also to understand the economic mechanism behind the facts."
  },
  {
    "objectID": "intro.html#empriical-validationinference-of-economic-theories-and-models",
    "href": "intro.html#empriical-validationinference-of-economic-theories-and-models",
    "title": "1¬† Introduce",
    "section": "2.3 Empriical validation/inference of economic theories and models",
    "text": "2.3 Empriical validation/inference of economic theories and models\nThe last step is to test the model by using the observed data and make inference about the model.The key is to transform the model into a textable empirical econometric model."
  },
  {
    "objectID": "intro.html#applications",
    "href": "intro.html#applications",
    "title": "1¬† Introduce",
    "section": "2.4 Applications",
    "text": "2.4 Applications\nAfter an econometric model passes the empirical evaluation, it can then be used to:\n\nExplain important empirical stylized facts\nTest economic theory and/or hypotheses\nForecast future evolution of the economy\nPolicy evaluation and other application"
  },
  {
    "objectID": "intro.html#the-simple-keynesian-consumption-function-modle",
    "href": "intro.html#the-simple-keynesian-consumption-function-modle",
    "title": "1¬† Introduce",
    "section": "4.1 The simple keynesian consumption function Modle",
    "text": "4.1 The simple keynesian consumption function Modle\nFor keynesian consumption function, we have the following model:\n\\[\nY_t = C_t + I_t + G_t\\\\\nC_t = \\alpha + \\beta Y_t + \\epsilon_t\n\\]\nWhere \\(Y_t\\) is the aggregate income,\\(C_t\\) is the private consumption,\\(I_t\\) is the private investment,\\(G_t\\) is the government expenditure,\\(\\epsilon_t\\) is the random error term.\nThe parameters \\(\\alpha\\) and \\(\\beta\\) can have appealing economic interpretations:\n\n\\(\\alpha\\) is the survival level consumption even if income is zero.\n\\(\\beta\\) is the marginal propensity to consume (MPC), i.e.¬†the amount of additional consumption for each additional unit of income.\n\nMultiplier of income with respect to govenrnment spending\n\\[\n\\frac{\\partial Y_t}{\\partial G_t} = \\frac{1}{1-\\beta}\n\\]\nwhich depends on the maginal propensity to consume \\(\\beta\\).So when assess the effect of fiscal policy, it is important to know the magnitude of \\(\\beta\\). ## Rational Expectations and Dynamic Asset Pricing Models\nThe rational expectations hypothesis (REH) is a key assumption in modern macroeconomics and finance. It states that agents‚Äô expectations about the future value of an economic variable are not systematically wrong. In other words, agents‚Äô expectations are not biased.\nSuppose a representative agent has a constant relative risk aversion utility function:\n\\[\nU =\\sum_{t=0}^{n} \\beta^{t}\n\\\\ u(C_t) =\\sum_{t=0}^{n} \\beta^t \\frac{C_t^{\\gamma} - 1}{\\gamma}\n\\]\nwhere \\(\\beta \\ge 0\\) is the discount factor and \\(\\gamma \\ge 0\\) is the coefficient of relative risk aversion.\\(\\mu(\\cdot )\\) is the agent‚Äôs utility function in each time period.\\(C_t\\) is consumption in period \\(t\\).\nSo, obviously the agent‚Äôs optimization problem is: choosing a sequence of consumption \\(\\{C_t\\}_{t=0}^{\\infty}\\) to maximize the expected utility \\[\n\\max_{\\{ C_t \\}} E(u)\n\\] subject to the budget constraint:\n\\[\nC_t + P_t q_t \\le W_t + P_t q_{t-1}\n\\]\nwhere \\(P_t\\) is the price of the consumption good in period \\(t\\), \\(q_t\\) is the quantity of the asset held at the end of period \\(t\\), and \\(W_t\\) is the wage income in period \\(t\\).\nSo we can define this marginal rate of intertemporal substitution (MRIS) as: \\[\nMRS_{t+1}(\\theta) = \\frac { \\frac { \\partial u ( C _ { t + 1 } ) } { \\partial C _ { t + 1 } } } {\\frac { \\partial u ( C _ { t } ) } { \\partial C _ { t } } } = (\\frac{C_{t+1}}{C_t})^{\\gamma-1}\n\\]\nwhere model parameter vector \\(\\theta = (\\beta,\\gamma)^{'}\\).\nSo the First order condition is: \\[\nE[\\beta MRS_{t+1}(\\theta)R_{t+1}|I_t] = 1\n\\]\nwhere \\(R_{t+1}\\) is the gross return on the asset in period \\(t+1\\) and \\(I_t\\) is the information set available at the beginning of period \\(t\\).And the FOC is usually called the Euler equation.And we can estimate this model by using the generalized method of moments (GMM) method.\n\n4.1.1 Production Function and Hypothsis on constant returns to scale\nProduction functionÔºö \\[\nY_t = \\exp(\\epsilon_t)F(L_t,K_t)\n\\]\nwhere \\(Y_t\\) is the output,\\(L_t\\) is the labor input,\\(K_t\\) is the capital input,\\(\\epsilon_t\\) is the random error term.\nSo we can get the constant return to scale hypothesis:\n\\[\n\\lambda F(L_i,K_i) = F(\\lambda L_i,\\lambda K_i) \\text{ for all } \\lambda &gt; 0\n\\]\nCRS is a necessary condition for the existence of a long-run equilibrium in a competitive market.If CRS does not hold, and the technology displays the increasing returns to scale, then the market will lead to natural monopoly.\nIn practical, a conventional approach to estimate the production function is to use the Cobb-Douglas production function: \\[\nY_i = F(L_i,k_i) = A \\exp(\\epsilon_i) L_i^{\\alpha}K_i^{\\beta}\n\\]\nThen CRS becomes a mathematical restriction on the parameters \\(\\alpha\\) and \\(\\beta\\): \\[\\mathbb{H}_0 : \\alpha + \\beta  = 1\\]\nSo if \\(\\alpha + \\beta &gt; 1\\), the production function displays increasing returns to scale; if \\(\\alpha + \\beta &lt; 1\\), the production function displays decreasing returns to scale.\nIn statistics, we can use the F-test to test the null hypothesis \\(\\mathbb{H}_0\\) (one dimensional restriction).\nunfortunately, this test is not suitable for many cross-sectional economic data, which usually display conditional heteroskedasticity.One needs to use a robust, heteroskedasticity-consistent test procedure, such as the White test."
  },
  {
    "objectID": "Foundation of Probability Theory.html#random-experiments",
    "href": "Foundation of Probability Theory.html#random-experiments",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.1 Random Experiments",
    "text": "2.1 Random Experiments\n[üí¨ Definition 1. Random Experiment] A random experiment is an experiment whose outcome is not known in advance.\nthere are two essential elements of a random experiment:\n\n\n\n\n\n\nImportant\n\n\n\nthe set of all possible outcomes\nthe likelihood of each outcome\n\n\nwe need to know the sample space and the probability of each outcome in the sample space.\n‚óè The purpose of mathematical statistics is to provide mathematical models for random experiments ofinterest.\n‚óè Once a model for such an experiment is provided and the theory worked out in detail, the statistician may,within this framework, make inference about the probability law of the random experiment."
  },
  {
    "objectID": "Foundation of Probability Theory.html#basic-concepts-of-probability",
    "href": "Foundation of Probability Theory.html#basic-concepts-of-probability",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.2 Basic Concepts of Probability",
    "text": "2.2 Basic Concepts of Probability\n[üí¨ Definition 2. Sample Space] The possible outconmes of a random experiment are called the sample space and is denoted by \\(S\\).\nWhen an experiment is performed, the realization of the experiment will be one (and only one) outcome in thesample space.(Mutually exclusive)\nIf the experiment is performed a number of times, a different outcome may occur each time or some outcomes may repeat.\na sample space \\(S\\) can be countable or uncountable.\n[üí¨ Definition 3. Event] An event \\(A\\) is a collection of basic outcomes from the sample space S that share certain common features or equivalently obey certain restrictions.\nThe event is the subset of the sample space.\n\n\n\n\n\n\nImportant\n\n\n\n\n\\(Basic outconme \\subseteq Event \\subseteq Sample\\ space\\)"
  },
  {
    "objectID": "Foundation of Probability Theory.html#review-of-set-theory",
    "href": "Foundation of Probability Theory.html#review-of-set-theory",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.3 Review of Set Theory",
    "text": "2.3 Review of Set Theory\n‚úÖUse Venn Diagram to represent the relationship between sets(or sample point,event, all the related concepts).\n[üí¨ Definition 4. Intersection] Intersection of \\(A\\) and B, denoted \\(A \\cap B\\)Ôºå is the set of basic outcomes in S that belong to both \\(A\\) and B.The intersection of \\(A\\) and B is the event that both \\(A\\) and B occur. is also called the logicall product of \\(A\\) and B.\n[üí¨ Definition 5. Exclusiveness] If \\(A\\) and B have no common basic outcomes, they are called mutually exclusive and their intersection is empty set \\(\\emptyset\\), i.e., \\(A \\cap B = \\emptyset\\) where \\(\\emptyset\\) denotes an empty set that contains nothing.\n\nmutually exclusive events are also called disjoint events.\n\n[üí¨ Definition 6. Union] The union of \\(A\\) and B, denoted \\(A \\cup B\\), is the set of basic outcomes in S that belong to either A or B or both. The union of A and B is the event that either A or B or both occur. is also called the logical sum of \\(A\\) and \\(B\\).\n[üí¨ Definition 7. Collective Exhaustiveness] Suppose that \\(A_1, A_2, A_3, \\cdots\\) are events in S. If \\(A_1 \\cup A_2 \\cup A_3 \\cup \\cdots = S\\), then the events \\(A_1, A_2, A_3, \\cdots\\) are collectively exhaustive.\n[üí¨ Definition 8. Complement] The complement of A, denoted \\(A^c\\), is the set of basic outcomes in S that do not belong to A. The complement of A is the event that A does not occur.\n\n\\(A \\cap A^{c} = \\emptyset \\ and \\ A \\cup A^{c} = S\\)\n\n[üí¨ Definition 9. Difference] The difference of A and B, denoted \\(A - B = A \\cap B^{c}\\), is the set of basic outcomes in S that belong to A but not to B. The difference of A and B is the event that A occurs but B does not occur.\nüßÆDistributivity Laws :\n\\[\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\\\\nA \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\n\\]\nIn more general, we have \\[\nB \\cap \\left( \\bigcup_{i=1}^{n} A_i \\right)= \\bigcup_{i=1}^{n} (B \\cap A_i) \\\\\nB \\cup \\left( \\bigcap_{i=1}^{n} A_i \\right)= \\bigcap_{i=1}^{n} (B \\cup A_i)\n\\]\nüßÆ De Morgan‚Äôs Laws\n\\[\n\\left( A \\cup  B \\right)^{c} =A^{c} \\cap B^{c}\n\\left( A \\cap  B  \\right)^{c} = A^{c} \\cup B^{c}\n\\]\nIn more general, we have \\[\n\\left( \\bigcup_{i=1}^{n} A_i \\right)^{c} = \\bigcap_{i=1}^{n} A_i^{c} \\\\\n\\left( \\bigcap_{i=1}^{n} A_i \\right)^{c} = \\bigcup_{i=1}^{n} A_i^{c}\n\\]\n\nüå∞: Suppose the events A and B are disjoint.Under what condition are \\(A^{c}\\) and \\(B^{c}\\) also disjoint?\nüëâ: \\(A^{c}\\) and \\(B^{c}\\) are disjoint if and only if \\(A \\cup B = S\\).That is say \\(A\\) and \\(B\\) is exhaustive.\nüå∞: ‚Ä¢ Are \\(A \\cap B\\) and \\(A^{c} \\cap B\\) mutually exclusive?\n‚Ä¢ Is \\(\\left( A \\cap B \\right) \\cup \\left( A^{c} \\cap B \\right) = B\\)?\n‚Ä¢ Are \\(A\\) and \\(A^{c} \\cap B\\) mutually exclusive?\n‚Ä¢ Is \\(A \\cup \\left( A^{c} \\cap B \\right) = A \\cap B\\)?\nüëâÔºöYes, Yes, Yes, No\nüå∞: Let the set of events \\(\\{ A_i = 1 , \\ldots ,n \\}\\) be mutually exclusive and collectively exhaustive, and let A be an event in S - Are \\(A_1 \\cap A, \\ldots ,A_n \\cap A\\) mutually exclusive? - Is the union of \\(A_i \\cap A, i = 1, \\ldots ,n\\), equal to A? That is, do we have: \\[\n\\bigcup_{i=1}^{n} \\left( A_i \\cap A \\right) = A\n\\]\nüëâ: Yes, Yes\n\nIn the linear algebra, we can use the projection matrix to understand this.The \\(\\{ A_1,A_2, \\ldots ,A_n \\}\\) is the orthogonal bases of the specific space, and the \\(A\\) is the vector in this space. The \\(A_i \\cap A\\) is the projection of \\(A\\) on the \\(A_i\\) direction.\n\nA sequence of collective and mutually exclusive events forms a partition of sample space S.\nA set of collectively exhaustive and mutually exclusive events can be viewed as a complete set of orthogonal bases.\nThe projection of a vector on a subspace is the sum of the projections of the vector on the orthogonal bases of the subspace.\nA complete set of orthogonal bases can represent any event A in the sample space S, and ùê¥ùëñ ‚à© ùê¥ could be viewed as the projection of event A on the base \\(A_i\\)."
  },
  {
    "objectID": "Foundation of Probability Theory.html#fundamental-probability-laws",
    "href": "Foundation of Probability Theory.html#fundamental-probability-laws",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.4 Fundamental Probability Laws",
    "text": "2.4 Fundamental Probability Laws\n‚úÖ To assign a probability to an event \\(A \\in S\\), we shall introduce a probability function, which is a function or a mapping from an event to a real number (0,1).\n‚úÖ To assign probabilities to events, complements of events,unions and intersections of events, we want our collection of events to include all these combinations of events.\n‚úÖSuch a collection of events is called an \\(\\sigma\\)-field(\\(\\sigma\\) algaebra) of subsets of the sample space S,which constitude the domain of the probability function.\n\n\n\nimage.png\n\n\n[üí¨ Definition 10. Sigma Algebra] A \\(sigma(\\sigma) algebra\\),denoted by \\(\\mathbb{B}\\) , is a collection of subsets(events) of S that satisfies the following three conditions:\n\n\\(\\emptyset \\in \\mathbb{B}\\)i.e., the empty set is in \\(\\mathbb{B}\\).\nIf \\(A \\in \\mathbb{B}\\), then \\(A^{c} \\in \\mathbb{B}\\).(i.e., \\(\\mathbb{B}\\) is closed under complements)\nIf \\(A_1,A_2, \\ldots \\in \\mathbb{B}\\), then \\(\\bigcup_{i=1}^{\\infty} A_i \\in \\mathbb{B}\\).(i.e., \\(\\mathbb{B}\\) is closed under countable unions)\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\\(\\sigma\\)-algebra is a collection of events in \\(S\\)(subset) that satisfies certain properties and constitutes the domain of a probability function.\nA \\(\\sigma\\) -field is a collection of subsets in \\(S\\) , but itself is not a subset of \\(S\\) . In contrast, the sample space \\(S\\) is only an element of a \\(\\sigma\\) -field.\nThe pair \\((S,\\mathbb{B})\\) is called a measurable space.So for a specific sample space \\(S\\), we can have different \\(\\sigma\\)-algebra \\(\\mathbb{B}\\).\n\n\n\n[üí¨ Definition 11. Probability Function] Suppose a random experiment has a sample space \\(S\\) and an associated \\(\\sigma\\) -field \\(\\mathbb{B}\\) . A probability function \\[\nP:\\mathbb{B} \\to [0,1]\n\\]\nis defined as a mapping that satisfies the following three conditions:\n\n\\(0 \\le P(A) \\le 1 for all A \\in \\mathbb{B}\\) .\n\\(P(S) = 1\\).\nIf \\(A_1,A_2, \\ldots \\in \\mathbb{B}\\) are mutually exclusive, then \\(P\\left( \\bigcup_{i=1}^{\\infty} A_i \\right) = \\sum_{i=1}^{\\infty} P(A_i)\\).üö©The probability of the union of mutually exclusive events is the sum of the probabilities of the individual events.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nA probability function tell how the probability of occurrence is distributed over the set of events \\(\\mathbb{B}\\).In this sense we speak of a distribution of probability.\n\n\n\n\n\n\n\nFor a given measurable space \\((S,\\mathbb{B})\\), many different probability functions can be defined. The goal of econometrics and statistics is to find a probability function that most accurately describes the underlying DGP. This probability function is usually called the true probability function or true probability distribution model.\n\n\n\n‚úÖSo how to interpret the probability target to an event?\n\n2.4.1 Approach 1:Relative frequency interpretation\nThe probability of an event can be viewed as the limit of the ‚Äù relative frequency‚Äù of occurrence of the event in a large number of repeated independent experiments under essentially the same conditions.\nThe relative frequency interpretation is valid under the assumption of a large number of repeated experiments under the same condition. In statistics, such an assumption is formally termed as ‚Äúindependence and identical distribution (IID)‚Äù.\n\n‚ÅâÔ∏è When the weather forecast bureau predicts that there is a 30% chance for raining, it means that under the same weather conditions it will rain 30% of the times. We cannot guarantee what will happen on any particular occasion, but if we keep records over a long period of time, we should find that the proportion of ‚Äúraining‚Äù is very close to 0.30 for the days with the same weather condition.\nBut in practical applications, we cannot repeat the same experiment a large number of times under the same conditions. Therefore, the relative frequency interpretation is not very useful in practice. We introduce the subjective interpretation of probability.\n\n\n\n2.4.2 Approach 2:Subjective Probability interpretation\nThe subjective method views probability as a belief in the chance of an event occurring.But a personal or subjective assessment is made of theprobability of an event which is difficult or impossible to estimate in any way.So is that means the subjective probability is not useful?\nüå∞: Subjective probability is the foundation of Bayesian statistics, which is a rival to classical statistics.\nüå∞: Rational Expectations\nRational expectations (Muth 1961) hypothesizes that the subjective expectation of an economic agent (i.e., the expectation under the subjective probability belief of the economic agent) coincides with the mathematical expectation (i.e., the expectation under the objective probability distribution).\nFor example, we eager to have a wage \\(S\\), but we don‚Äôt know the exact value of \\(S\\). We can only estimate the probability distribution of \\(S\\) based on our subjective probability belief. The rational expectation hypothesis states that the subjective expectation of \\(S\\) is equal to the mathematical expectation of wage :the \\(E(S)\\).\nüå∞: Professional Forecast\nThe U.S. central bank‚ÄîFed issues professional forecasts for important macroeconomic indicators such as GDP growth rate, inflation rate and unemployment rate.\nIn each quarter, they send surveys to professional forecasters, asking their views on probability distributions of these important macroeconomic indicators.\nSpecifically, each forecaster will be asked what is his/her forecast of the probability that the inflation rate lies in various intervals.\nüå∞: Risk Neutral Probability\nDuring the 1997-1998 Asian financial crisis, many investors were very concerned with the collapse of the Hong Kong peg exchange rate system with U.S. dollars and devaluations of Hong Kong dollars.\n\n\n\n\n\nIn other words, their subjective probabilities of Hong Kong dollar devaluation were higher than the objective probabilities of the Hong Kong dollar movements. The former are called risk-neutral probability distributions and the latter are called objective or physical probability distributions in finance.\n\n\n\n\n\nThe gap between these two distributions reflects the risk attitude of market investors. The risk-neutral probability distribution is a financial instrument in derivative pricing.\n\n\n\n\n\n[üí¨ Definition 12. Probability Space] A probability space is a triple \\((S,\\mathbb{B},P)\\), where \\(S\\) is a sample space, \\(\\mathbb{B}\\) is a \\(\\sigma\\)-field of subsets of \\(S\\), and \\(P:\\mathbb{b} \\to [0,1]\\) is a probability function defined on \\(\\mathbb{B}\\).\n\nBecause the probability function \\(P(\\cdot )\\) is defined on \\(\\mathbb{B}\\), the collection of sets (i.e., events), it is also called a set function.\n\n‚öñÔ∏è Theorem 1 If \\(\\emptyset\\) denotes the empty set, then \\(P(\\emptyset) = 0\\).\nüìë Proof: Given that ùëÜ = ùëÜ ‚à™ ‚àÖ, and ùëÜ and ‚àÖ are mutually exclusive, we have \\(P(S) = P(S \\cup \\emptyset) = P(S) + P(\\emptyset)\\).It follows that \\(P(\\emptyset) = 0\\).\n\n\n\n\n\n\nWarning\n\n\n\n\\[\nP(A) = 0 \\text{**does not**} \\Rightarrow A = \\emptyset\n\\]\n\n\n‚öñÔ∏è Theorem 3 \\(P(A) = 1 - P(A)^{c}\\)\nüìë Proof: Oberve \\(A \\cup A^{c} = S\\). Then \\[\nP(S) = P(A \\cup A^{c}) = P(A) + P(A^{c})\n\\] Because \\(P(S)=1\\),\\(A \\text{and} A^{c}\\) are mutually exclusive, we have \\(P(A) = 1 - P(A^{c})\\).\n\n\n\n\n\n\nImportant\n\n\n\nThe ratio of the probability of an event \\(A\\) to the probability of its complement, \\[\n\\frac{P(S)}{P(A^{c}) }  =\\frac{P(A)}{1- P(A)}\n\\] is called the ratio odds of \\(A\\).\n\n\n‚öñÔ∏è Theorem 4 If \\(A\\) and \\(B\\) are two events in \\(\\mathbb{B}\\), and \\(A \\subseteq B\\), then \\[\nP(A) \\le P(B)\n\\]\n‚öñÔ∏è Theorem 5 For any two events \\(A\\) and \\(B\\) in \\(\\mathbb{B}\\), \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\\] Keep in mind that the probability of an event is equal to the area it occupies in the sample space.\nSince \\(A \\cap B \\subseteq S\\), we have \\(P(A \\cap B) \\le P(S) = 1\\) by Theorem 4. It follows from the theorem 5 that\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B) \\ge P(A) + P(B) - 1\n\\]\nIt also called the Bonferroni‚Äôs inequality.\n‚öñÔ∏èÔ∏è Theorem 6 [Rule of total probability] If \\(A_1,A_2, \\ldots \\in \\mathbb{B}\\) are mutually exclusive and collectively exhaustive, and A is an event in \\(S\\), then \\[\nP(A) = \\sum_{i=1}^{\\infty} P(A \\cup A_i)\n\\]\n\n\n\n\n\nSo if \\[\nA = \\{ \\text{students whose scores &gt; 90 points} \\},\\\\\nA_i = \\{ \\text{students from country i} \\}\n\\]\nthen \\(A \\cap A_i = \\{ \\text{students from country i whose scores are &gt; 90 points} \\}\\)\n‚öñÔ∏è Theorem 7 [Subadditivity:Boole‚Äôinequality] For any sequence of events \\(\\{ A_i \\in \\mathbb{B}, i =1,2, \\ldots \\}\\), \\[\nP \\left(  \\bigcup_{i=1}^{\\infty}A_i  \\right)  \\le \\sum_{i=1}^{\\infty} P(A_i)\n\\]"
  },
  {
    "objectID": "Foundation of Probability Theory.html#methods-of-counting",
    "href": "Foundation of Probability Theory.html#methods-of-counting",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.5 Methods of Counting",
    "text": "2.5 Methods of Counting\n‚úÖHow to calculate the probability of event A?\nSuppose event \\(A\\) includes \\(k\\) basic outcomes in the sample space \\(S\\). Then the probability of \\(A\\) is given by \\[\nP(A) = \\sum_{i=1}^{k}P(A_i)\n\\]\nIf in addition \\(S\\) consists of \\(n\\) equally likely basic outcomes \\(\\{ A_1, \\ldots ,A_n\\}\\), and event \\(A\\) consists of \\(k\\) basic outcomes, then"
  },
  {
    "objectID": "Foundation of Probability Theory.html#conditional-probability",
    "href": "Foundation of Probability Theory.html#conditional-probability",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.6 Conditional Probability",
    "text": "2.6 Conditional Probability"
  },
  {
    "objectID": "Foundation of Probability Theory.html#bayes-theorem",
    "href": "Foundation of Probability Theory.html#bayes-theorem",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.7 Bayes‚Äô Theorem",
    "text": "2.7 Bayes‚Äô Theorem\n‚úÖ The knowledge that an event B has occurred can be used to revise or update the prior probability that an event A will occur.\n‚úÖ Bayes‚Äô theorem describes the mechanism of revising or updating the prior probability learning.\n‚úÖ This theorem leads to the Bayesian school of statistics, a rival to the school of classical statistics.\n‚öñÔ∏è Theorem 11 [Baye‚Äôs Theorem] Suppose A and B are two events with \\(P(A) &gt; 0\\) and \\(P(B) &gt; 0\\). Then \\[\nP(A|B) = \\frac{P(B|A)P(A)}{P(B)} = \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^{c})P(A^{c}) }\n\\]\n\n\n\n\n\n\nImportant\n\n\n\n\\(P(A)\\) is called a ‚Äù prior‚Äù probability (i.e., before the fact or evidence) about event A since it is the probability of A before new information B arrives.\nThe conditional probability \\(P(A|B)\\) is called a ‚Äúposterior‚Äù probability (i.e., after the fact or evidence) since it represents the revised assignment of probability of A after the new information that B has occurred is obtained.\n\n\n‚öñÔ∏è Theorem 12 [Alternative Statement of Bayes‚Äô Theorem]  Suppose \\(A_1, \\ldots ,A_n\\) are \\(n\\) mutually exclusive and collectively exhaustive events in the sample space \\(S\\), and \\(A\\) is an event with \\(P(A) &gt; 0\\). Then the conditional probability of \\(A_i\\) given \\(A\\) is \\[\nP(A_i|A) = \\frac{P(A|A_i)P(A_i)}{\\sum_{j=1}^{n}P(A|A_i)P(A_i) }, \\quad i = 1,2, \\ldots ,n\n\\]\nüå∞: How to Determine Auto-insurance Premium?\nSuppose an insurance company has three types of customers‚Äîhigh risk, medium risk and low risk. From the company‚Äôs historical consumer database, it is known that 25% of its customers are high risk, 25% are medium risk, and 50% are low risk. Also, the database shows that the probability that a customer has at least one speeding ticket in one year is 0.25 for high risk, 0.16 for medium risk, and 0.10 for low risk.\nNow suppose a new customer wants to be insured and reports that he has had one speeding ticket this year. What is the probability that he is a high risk customer, given that he has had one speeding ticket this year?"
  },
  {
    "objectID": "Foundation of Probability Theory.html#independence",
    "href": "Foundation of Probability Theory.html#independence",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.8 Independence",
    "text": "2.8 Independence\n[üí¨ Definition 13. Independence] Two events \\(A\\) and \\(B\\) are independent if and only if \\(P(A \\cap B) = P(A)P(B)\\)\n\n\n\n\n\n\ndifference between mutally exclusive and independence\n\n\n\nmutually exclusive means the \\(P(A\\cap b) \\equiv 0\\) , the occrance of event \\(A\\) means the disappear of event \\(B\\) , but the independence means \\(P(A\\cap b) \\equiv P(A)P(B)\\).Independence is a probability notion to describe nonexistence of any kind of relationship between two events. It plays a fundamental role in probability theory and statistics. But two independent event may occur at the same time.\n\n\n\nSuppose \\(P(B)&gt;0\\).They by definition of independence:\n\\[\nP(A|B) = P(A \\cap B)\n= \\frac{P(A)P(B)}{P(B) }\n= P(A)\n\\]\nthis formula shows that the conditional probability of \\(A\\) given \\(B\\) equal to the unconditional probability of \\(A\\).The knowledge of \\(B\\) does not help in predicting \\(A\\).Similarly, we have \\(P(B|A) = P(B)\\), i.e.¬†the occurrence of \\(A\\) has no effect on the occurrence or probability of \\(B\\).Intuitively, independence implies that \\(A\\) and \\(B\\) are ‚Äúirrelevant‚Äù, or there exists no relationship between them.\nüå∞:Random Walk hypothesis(Fama 1970) A stock Price \\(P_t\\) will follow a random walk if \\[\nP_t = P_{t-1} + X_t\n\\]\nwhere the \\(\\{ X_t \\}\\) is the independent across different time period.\n\nNote that here the \\(X_t = P_t - P_{t-1}\\) is the stock price change from the \\(t-1\\) to time \\(t\\)\n\nNow we have a closely related concept : the geometric random walk.The stock price \\(\\{ P_t \\}\\) is called a geoemtric random walk if \\[\n\\ln P_t = \\ln P_{t-1} + X_t\n\\]\n\\(\\{ X_t \\}\\) is independent across different time period.\nThe increment of the geometric random walk is \\[\nX_t = \\ln (\\frac{P_t}{P_{t-1} })\n= \\ln (1 + \\frac{P_t - P_{t-1} }{P_{t-1} })\n\\simeq \\frac{P_t - P_{t-1}}{P_{t-1}}\n\\]\ncan be interpreted as the relative stock price change.In long term time series analysis, the geometric random walk is more popular than the random walk because the relative stock price change is more stable than the absolute stock price change.\n‚öñÔ∏è Theorem 13  Let \\(A\\) and \\(B\\) are two independent events. Then\n\n\\(A\\) and Bc are independent\n\\(A^{c}\\) and \\(B\\) are independent\n\\(A^{c}\\) and \\(B^{c}\\) are independent\n\n[üí¨ Definition 15 Independence Among Several Events] \\(k\\) events \\(A_1,A_2, \\ldots ,A_n\\) are mutually independent if, for every possible subset \\(A_{i_1}, \\ldots ,A_{i_j}\\) of \\(j\\) of those events \\((j =2,3, \\ldots ,k)\\), \\[\nP(A_{i_1} \\cap \\cdots \\cap A_{i_j}) = P(A_{i_1}) \\times \\cdots \\times P(A_{i_j})\n\\]\n\nFor three or more events, independence is called mutual independence or joint independence. If there is no possibility of misunderstanding, independence is often used without the modifier ‚Äúmutual‚Äù or ‚Äújoint‚Äù when considering several events. \n\nüå∞: Three events \\(A,B\\)and \\(C\\) are independent, if the following \\(2^{3} - (1+3) = 4\\) conditions are satisfied (\\(1 \\text{means the } \\emptyset \\text{ and the} 3 \\text{means the single element set}\\)):\n\n\\(P(A \\cap B) = P(A)P(B)\\)\n\\(P(A \\cap B) = P(A)P(C)\\)\n\\(P(B \\cap C) = P(B)P(C)\\)\n\\(P(A \\cap B \\cap C ) = P(A)P(B)P(C)\\)\n\nüå∞: Complementarity Between Economic Reforms\nIn the fields of economic growth and development, many studies find that one economic policy usually necessities another policy to stimulate the economic growth, which is called policy complementarities. In traditional economics, individual reforms or sequential reforms may not be effective or fully effective, or even back-ring. Reforms must be packed together in order to be effective. Foundation of Probability Theory Independence\nFor example, in order to improve firm productivity (\\(A_1\\)), changing a manager (\\(A_2\\)) should be together with granting autonomy to the firm (\\(A_3\\)).\n\nThere are many other examples of economic complementarities. Harrison (1996), Ro-driguez and Rodrik (2000), Loayza et al.¬†(2005), Chang et al.¬†(2005) document that international trade openness, only when combined with other policies that improve a country‚Äôs educational investment, financial depth, inflation stabilization, public infrastructure, governance, labor market flexibility, and ease of firm entry and exit, can promote economic growth."
  },
  {
    "objectID": "Foundation of Probability Theory.html#conclusion",
    "href": "Foundation of Probability Theory.html#conclusion",
    "title": "2¬† Foundation of Probability Theory",
    "section": "2.9 Conclusion",
    "text": "2.9 Conclusion\n‚úÖ This chapter is a foundation of probability theory.\n‚úÖ We first characterize a random experiment by a probability space \\((S, \\mathbb{B}, P)\\). Interpretations for probabilities are provided.To the probability function, we need to estimate it from data to get a true probability function\n‚úÖ Given a measurable space \\((ùëÜ, ùîπ)\\), one can dene many probability functions. The main objective of econometrics is to use the observed economic data to infer a suitable probability function which truly represents the true probability distribution for the data generating process.\n‚úÖ For random experiments with equally likely outcomes, methods of counting are very useful in calculating probabilities of interested events.\n‚úÖ The conditional probability function characterizes predictive relationships between or among economic events. An application is Bayes‚Äô theorem.\n‚úÖ Finally, we introduce the concept of independence and its implications in economics and finance."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3¬† Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "Foundation of Probability Theory.html",
    "href": "Foundation of Probability Theory.html",
    "title": "2¬† Foundation of Probability Theory",
    "section": "",
    "text": "3 Independence\n** [üí¨ Definition 13. Independence]** Two events \\(A\\) and \\(B\\) are independent if and only if \\(P(A \\cap ) = P(A)P(B)\\)\nSuppose \\(P(B)&gt;0\\).They by definition of independence:\n\\[\nP(A|B) = P(A \\cap B)\n= \\frac{P(A)P(B)}{P(B) }\n= P(A)\n\\]\nthis formula shows that the conditional probability of \\(A\\) given \\(B\\) equal to the unconditional probability of \\(A\\).The knowledge of \\(B\\) does not help in predicting \\(A\\).Similarly, we have \\(P(B|A) = P(B)\\), i.e.¬†the occurrence of \\(A\\) has no effect on the occurrence or probability of \\(B\\).Intuitively, independence implies that \\(A\\) and \\(B\\) are ‚Äúirrelevant‚Äù, or there exists no relationship between them."
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#random-variables",
    "href": "Random Variables and Univariate Probability Distributions.html#random-variables",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.1 Random Variables",
    "text": "3.1 Random Variables\n‚úÖ It is inconvenient to work with different sample spaces. To develop a unified probability theory, we consider a mapping \\(X\\) from the original sample space \\(S\\) to a new sample space \\(\\Omega\\) which consists of a set of real numbers.This transformation \\(X:S \\to \\Omega\\) is called a random variable. &gt; The nature of random variable is a function or a map\n‚úÖ In many applications, we may be interested only in some particular aspect of the outcomes of an experiment, rather than the outcomes themselves. \\(A\\) suitably defined random variable \\(X\\) will better serve for our purpose.\n\n3.1.1 Defination of Random Variable\n[üí¨ Definition 1. Random Varible] A random variable,\\(X(\\cdot )\\), is a \\(\\mathbb{B}\\)-measurable mapping (or point function) from the sample space \\(S\\) to the real line \\(\\mathbb{R}\\) such that for each outcome \\(s \\in S\\), there exists a corresponding unique real number, \\(X(s)\\). The collection of all possible values that the random variable \\(X\\) can take, also called the range of \\(X(\\cdot )\\),constitutes a new sample space, denoted as \\(\\Omega\\).\n\n\n\n\n\n\nImportant\n\n\n\n\\[\nX:S \\to \\Omega \\text{ need not be 1-1 mapping. \\\\\nIt is possible that }X(s_1) = X(s_2)\n\\]\nConvention:A capital letter \\(x\\) denotes a random variable,and a lowercase letter \\(x\\) denotes its realization,i.e., a possible value that random variable \\(X\\) can take (i.e., \\(x =X(s)\\)for \\(a\\) given \\(s \\in S\\)).\n\n\nüå∞:When we throw a coin, the sample space \\(S = \\{ H,T \\}\\). Define a random variable \\(X(\\cdot )\\) by $X(H) =1 $ and \\(X(T) = 0\\). Then we obtain a new sample space \\(\\Omega = \\{ 1,0 \\}\\)\nFor the election of a candidate, the sample sapces \\(S = \\{ Win,Fail \\}\\). Define a random variable \\(X(\\cdot )\\) by $X(Win) =1 $ and \\(X(Fail) = 0\\). Then we obtain a new sample space \\(\\Omega = \\{ 1,0 \\}\\)\nSo it is not necessary to have the same number of basic outcomes for both \\(S\\text{ and } \\Omega\\)\nSuppose we throw three fair coins.Then the space sample \\(S=\\{TTT,TTH,THT,HTT,HHT,HTH,THH,HHH\\}\\) Let \\(X(\\cdot)\\) be the number of heads shown up.Then \\(X(TTT)= 0,\\)\\(X(TTH)=1,\\)\\(X(THT)=1,\\)\\(X(HTT)=1,\\)\\(X(HHT)= 2,\\)\\(X(HTH)=2,\\)\\(X(THH)2,\\)\\(X(HHH)=3\\).We have \\(\\Omega = \\{ 0,1,2,3 \\}\\).\nSuppose \\(S = \\{ s:-\\infty &lt; s &lt; +\\infty \\}\\). Define \\(X(s) = 1\\) if \\(s &gt; 0\\) and \\(X(s) = 0\\) if \\(s \\le 0\\)\n\nHere \\(X\\) is called binary random variable because there are only two possible values \\(X\\) can take.The binary variable has wide applications in economics.\n\nThere are many other examples of random variables, including - subjective well-being - sentiment index of investoers - economic policy uncertainty(EPU) index\nThese indices are usually constructed based on text data from social media platforms (e.g.,WeChat,Facebook)and news media.Text data are an unstructured form of Big data.\n\n\n\n3.1.2 Probability Function of the new sample space \\(\\Omega\\)\nThe probability function defined on the original sanple space \\(S\\) can be uesd to obtain the probability function of the new sample space \\(\\Omega\\).\nFirst suppose space \\(S\\) has a finite number of basic outcomes\n\\[\nS = \\{ s_1,s_2, \\ldots ,s_n \\}\n\\]\nwith a probability function \\(P:\\mathbb{B} \\to [0,1]\\), where \\(\\mathbb{B}\\) is a \\(\\sigma\\)-field associated with \\(S\\). Define a random variable \\(X(\\cdot ) : S \\to \\mathbb{R}\\) by \\(X(s_i) = x_i\\) for \\(i = 1,2,\\ldots ,n\\) Then the new sample space \\(\\Omega\\) is given by\n\\[\n\\Omega \\{ x_1, \\ldots ,x_m \\}\n\\]\nwhere \\(m\\) may not be the same as \\(n\\).\nThen the probability function \\(P_{X}:\\Omega \\to \\mathbb{R}\\) for \\(X\\) can be obtained as\n\\[\nP_{X}(x_i) \\equiv P(X = x_i) = P(C_i)\n\\]\nwhere \\(C_i\\) is an event in \\(S\\) such that:\n\\[\nC_i = \\{ s \\in S : X(s) = x_i \\}\n\\]\n\\(P_{X}(\\cdot )\\) is induced probability function on the new sample space \\(\\Omega\\), obtained from the original probability function \\(P(\\cdot )\\)\nMore formally, for any set \\(A \\in \\mathbb{B}_{\\Omega}\\),where \\(\\mathbb{B}_{\\Omega}\\) is a \\(\\sigma\\)-field generated from \\(\\Omega\\), we can define a probability function \\(P_{X}(\\cdot ): \\mathbb{B}_{\\Omega} \\to \\mathbb{R}\\) on \\(\\Omega\\) as follows: \\[\nP_{X}(A) = P(C_{A}) = P[s \\in S : X(s) \\in A]\n\\]\nwhere \\(C_{A} = \\{ s \\in S:X(s) \\in A \\}\\), which is an equivalent event in \\(S\\).\nNow we complete the transformation from the original measurable space \\((S,\\mathbb{B},P)\\) to the new space \\((\\Omega,\\mathbb{B}_{\\Omega},P_X)\\).\nüí¨ Definition 3.2 Measurable Function A function \\(X:S \\to \\mathbb{R}\\) is \\(\\mathbb{B}\\)-measurable(or measurable with respect to the \\(\\sigma\\)-field $ $ generated from \\(S\\)) if for every real number \\(a\\), the set \\(\\{ s \\in S : X(s) \\ge a \\} \\in B\\)\n\nA \\(\\mathbb{B}\\)-measurable function is simply called a measurable function.(if it dose not cause any confusion)\nA measurable function ensures that \\(P(X \\in A)\\) is always well-defined for all subsets \\(A\\) in \\(\\mathbb{B}_{\\Omega}\\)\nIf \\(X(\\cdot )\\) is not measurable, then there exist subsets in the \\(\\sigma\\)-field in \\(\\mathbb{R}\\) for which probability are not defined .\nIn this doc, the term ‚Äúrandom variable‚Äù is restricted to being a \\(\\mathbb{B}\\)-measurable function from \\(S\\) to \\(\\mathbb{R}\\)\n\n‚öñÔ∏èTheorem 3.1 Let \\(\\mathbb{B}\\) be a \\(\\sigma\\)-algebra associated with sample spaces \\(S\\).Let \\(f(\\cdot )\\) and \\(g(\\cdot )\\) be \\(\\mathbb{B}\\)-measurable real valued functions, and \\(c\\) be a real number.Then the function \\(f(\\cdot ) + g(\\cdot )\\),\\(cf(\\cdot )\\),\\(f( \\cdot )\\cdot g( \\cdot )\\),\\(\\left\\vert f( \\cdot ) \\right\\vert\\)are also \\(\\mathbb{B}\\)-measurable.\n\nif function \\(X( s )\\) and \\(Y( s )\\) are measurable mappings from \\(S\\) to \\(\\Omega\\), then the ordinary algebraic operations on \\(X( s )\\) and \\(Y( s )\\) will produce new measurable mappings. - \\(aX( s )\\) - \\(X( s ) + Y( s )\\) - \\(X( s )Y( s )\\) and \\(\\frac{X( s )}{ Y( s )}\\)\n\n‚ÅâÔ∏èÔ∏è The induced probability function \\(P_{x}( \\cdot )\\) satisfies the three axioms of the probability function?\n\n\n\n\n\n\nTip\n\n\n\n\nCondition ( 1 ) \\[\n1 \\ge P_{X}(x_i) = P(X = x_i) = P(C_i) \\ge 0\n\\]\n\ngiven \\(0 \\le P( C_{A} ) \\le 1\\) for any \\(C_{A} \\in \\mathbb{B}\\), where \\(\\mathbb{B}\\) is a \\(\\sigma\\)-field associated with \\(S\\).\n\nCondition ( 2 ) \\[\nP_{X}( \\Omega ) = P( S ) = 1\n\\]\nCondition ( 3 )\n\nconsider two mutually exclusive events \\(A_1\\) and \\(A_2\\) in \\(\\mathbb{B}_{\\Omega}\\), a \\(\\sigma\\)-field generated from \\(\\Omega\\). Here, the induced probability of \\(A_1 \\cap A_2\\) is given by \\[\nP_{X}( A_1 \\cap  A_2 ) = P( C )\n\\]\nwhere \\(C = \\{ s\\in S: X( s ) \\in A_1 \\cap A_2 \\}\\)\nHowever, we can also write \\[\nC = \\{ s \\in S : X( s ) \\in A_1 \\} \\cap \\{ s \\in S : X( s ) \\in A_2 \\} \\\\\n= C_1 \\cap C_2\n\\]\nThe fact that \\(A_1\\) and \\(A_2\\) are disjoint implies that \\(C_1\\) and \\(C_2\\) are also disjoint. It follows that\n\\[\nP_{x}( A_1 \\cap A_2  ) = P( C_1 ) + P( C_2 ) \\\\\n= P_{x}( A_1 ) + P_{X}( A_2 )\n\\]\n\n\nIn the rest, we will abuse the notations for the original probability function \\(P( \\cdot )\\) and the induced probability function \\(P_{X}( \\cdot )\\); we will denote both probability functions as \\(P( \\cdot )\\)\nüå∞: Suppose we throw three coins. Then the sample space \\[\nS = \\{ HHH,HTH,HHT,THH,THT,TTH,HTT,TTT \\}\n\\]\nDefine a random variable \\(X( \\cdot )\\) to be the number of the heads obtained from the experiment. Then the new sample space, or the range of \\(X\\), is given by\n\\[\n\\Omega = \\{ 0,1,2,3 \\}\n\\]\nNow, suppose we are interested in calculating the probability that \\(P( 0 \\le X \\le 1 )\\).Denote\n\\[\nC = \\{ s \\in S: 0 \\le X( s ) \\le 1\\}\\\\\n= \\{ TTT,TTH,THT,HTT\\}\n\\]\nIt follows that: \\[\nP(0 \\le X \\le 1 ) = P( C )\\\\\n= \\frac{1}{2 }\n\\]"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#cumulative-distribution-function",
    "href": "Random Variables and Univariate Probability Distributions.html#cumulative-distribution-function",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.2 Cumulative Distribution Function",
    "text": "3.2 Cumulative Distribution Function\n‚úÖ How to characterize a random variable \\(X\\)?\nüí¨ Definition 3.3 cumulative Distribution Function (CDF) The cumulative distribution function (CDF) of a random variable \\(X\\) is defined as \\[\nF_{X}(x) = P( X \\le x ) \\text{ for all } x \\in \\mathbb{R}\n\\]\n‚öñÔ∏èTheorem 3.2 Properties of \\(F_{X}( \\cdot )\\) Suppose \\(F_{X}( \\cdot )\\) is the CDF of some random variable \\(X\\).\n\n\\(\\lim_{x \\to -\\infty}F_{X}( x ) = 0,\\lim_{x \\to +\\infty}F_{X}( x )=1\\).\n\\(F_{X}( x )\\) is non-decreasing\n\\(F_{X}( x )\\) is right-continuous, i.e., for all \\(x\\) and \\(\\delta&gt;0\\) ,\n\n\\[\n\\lim_{\\delta \\to 0^{+}}[F_{X}(x+\\delta-F_{X}( x )] = 0\n\\]\n‚öñÔ∏è Theorem 3.3 Let \\(a&lt;b\\).Then \\[\nP(a&lt;X \\le b) = F_{X}( b ) - F_{X}( a )\n\\]\n‚öñÔ∏è Theorem 3.4 \\(P( X &gt; b ) = 1 - F_{X}( b )\\)\nüå∞: Suppose \\(F_1( x )\\) and \\(F_2(x)\\) are two CDF‚Äôs. Is the linear combination \\(F( x ) = pF_1( x ) +(1-p)F_2(x)\\) a CDF?Here p is a constant\nIIF the \\(0 \\le p\\le 1\\)\n\n\n\n\n\n\nMixture of two distributions\n\n\n\n\nA mixture of two distributions can provide a great deal of flexibility such as capturing skewness and heavy tails.\nOne possibility for a mixed distribution to arise is that in an observed data, some observations are generated from one distribution, and the remaining observations are generated from another distribution.\nAnother possibility for a mixed distribution is that there exist two mutually exclusive states,state 1 and state 2 which arise with probabilities p and 1 -p respectively.The random variable \\(X\\) will follow the distribution \\(F(x)\\) when state 1 occurs and will follow distribution \\(F_2(x)\\) when state 2 occurs.Then the distribution \\(F(x)\\)of \\(X\\) is a mixture of distributions \\(F_1(x)\\)and \\(F_2(x)\\).\nA well-known example in econometrics is the so-called Markov regime-switching model, which is widely used in macroeconomics and finance, in which \\(p\\) depands on a state variable characterizing the business cycles\n\n\nIn practice, \\(p\\) may depend on some economic variables \\(Z\\). An example of \\(p = p( Z )\\) is\n\\[\np( Z ) = \\frac{1}{1 + \\exp( - \\alpha^{'} Z )}\n\\]\n\n\n\nüí¨ Definition 3.4 Identical Distributions Two random variables \\(X\\) and \\(Y\\) are identically distributed if for every set \\(A\\) in \\(\\mathbb{B}_{\\Omega}\\), where \\(\\mathbb{B}_{\\Omega}\\) is the smallest \\(\\sigma\\)-field containing all the the intervals of real numbers of the form \\(( a,b ),[a,b),(a,b],\\) and \\([a,b]\\), one has \\[\nP( X \\in A ) = P( Y \\in A )\n\\]\n\nit is important to note that the identically distribution does not imply \\(X = Y\\), although \\(X = Y\\) implies that \\(X\\) and \\(Y\\) have the same distribution\nit is not necessary that \\(X\\) and \\(Y\\) are defined on the same sampele space. Only their distributions functions have to coincide.\n\n‚öñÔ∏è Theorem 3.5 Let \\(X\\) and \\(Y\\) be two random variables defined on the same sample space \\(S\\).Then \\(X\\) and \\(Y\\) are identically distributed if and only if their CDF‚Äôs are identical, i.e., \\(F_{X}( x ) = F_{Y}( x )\\) for all \\(x \\in \\mathbb{R}\\)\nüå∞:the Income distribution, Lorenz Curve and Gini Coefficient\nIn economics, the Lorenz curve and Gini coefficient are two popular measures of income income inequality.\n\\[\n\\text{Gini coefficient} = \\frac{A}{A+B}\n\\]\n\n\n\nLorenz Curve.png\n\n\nIt graphically shows that for the bottom \\(x%\\) of households, what percentage \\(y%\\) of the total income they share. Every point on the Lorenz curve represents a statement like ‚Äúthe bottom \\(20%\\) of all households have \\(10%\\) of the total income‚Äù\nA perfectly equal income distribution would be one in which every household has the same income. In this case, the bottom \\(x%\\) of society would always have \\(x%\\) of the income for all \\(x \\in [0,100]\\). This can be depicted by the 45-degree straight line \\(y=x\\), called the ‚Äúline of the perfect equality‚Äù\n\nIn economics, the Gini coefficient is the most commonly used measurement of inequality. It was developed by the Italian statistician and sociologist Corrado Gini in 1912. The Gini coefficient is defined based on the Lorenz Curve.The Gini coeffcient can then be thought of as the ratio of the area that lies between the line of equality and the Lorenz curve over the total area under the line of equality If all people have non-negative income ( or wealth ), the Gini coefficient can theoretically range from 0( complete equality ) to 1( complete inequality ); it is sometimes expressed as a percentage ranging between 0 and 100 If negative values are possible ( such as the negative wealth of people with debts ), then the Gini coefficient could theoretically be more than 1. Noting that two countries with different income distributions can have the same Gini coefficient\n\nüå∞: First Order Stochastic dominance\nIf two distribution \\(F( \\cdot )\\) and \\(G( \\cdot )\\) satisfy \\(F( x ) \\le G( x )\\) for all \\(x\\) on the real line, with strict inequality at least for some \\(x\\), then we say that the distribution \\(F( \\cdot )\\) has first order stochastic dominance over dsitribution \\(G( \\cdot )\\)\n\n\n\nFirst-order Stochastic dominance.png\n\n\n\nthe first order stochastic dominance is widely used in decision analysis, welfare economics, and finance An application of stochastic dominance is to the analysis of income distributions. If \\(x\\) denotes an income level, then the inequality means that the proportion of individuals in distribuion \\(F( \\cdot )\\) with the income less than \\(x\\) is smaller than the proportion of such individuals in \\(G( \\cdot )\\). In other words, there is a higher proportion of poorer people in \\(G( \\cdot )\\) than in \\(F( \\cdot )\\) Another application:if portfolio \\(F( \\cdot )\\)has first order stochastic dominate over portfolio \\(G( \\cdot )\\),then \\(P_{F}( X &gt; x ) \\ge P_{G}( X &gt; x )\\) for all \\(x\\);that is,the probability that high returns of portfolio \\(F( \\cdot )\\) is higher than the probability that high returns of portfolio \\(G( \\cdot )\\).\n\nüå∞: Second order stochastic Dominance A probability distribution \\(F( \\cdot )\\) stochastically domiance another probability distribution \\(G( \\cdot )\\) to second order if, for all \\(x \\in ( -\\infty,+\\infty )\\), \\[\n\\int_{-\\infty}^{x}F( y )dy \\le \\int_{-\\infty}^{x}G( y )dy,\n\\]\nwith strict inequality for at least some \\(x\\). This defination requires the dominant distribution \\(F( \\cdot )\\) to have a smaller area beneath the distribution function for all \\(x\\).\n\n\n\nSecond-order stochastic dominance.png\n\n\n\nRisk-averse economic agents will always prefer distribution \\(F( \\cdot )\\) because for any increasing and concave utility function \\(u( \\cdot )\\), we have \\[\n\\int_{-\\infty}^{\\infty}u( x )dF(x) \\ge \\int_{-\\infty}^{\\infty} u( x )dG( x )\n\\]\n\nif and only if \\(F( \\cdot )\\) has second order stochatic dominance over \\(G( \\cdot )\\)\n\n\n\n\n\n\nTip\n\n\n\nIntuitively,economic agents whom prefer more will prefer a first order stochastic dominating distribution,and economic agents who prefer more but are risk-adverse will prefer a second order stochastic dominating distribution.\nHigher order stochastic dominance can be defined in a similar way.\nThe concepts of various stochastic dominances are very useful in characterizing risk behavior of economic agents.There exists a dual relationship between stochastic dominances and classes of utility functions.\nProbability theory is a rather useful analytic tool in behavior economics and behavior finance."
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#discrete-random-variablesdrv",
    "href": "Random Variables and Univariate Probability Distributions.html#discrete-random-variablesdrv",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.3 Discrete Random Variables(DRV)",
    "text": "3.3 Discrete Random Variables(DRV)\nüí¨ Definition 3.5 Discrete Random Variable(DRV) If a random variable \\(X\\) can only take a countable number of values, then \\(X\\) is called a discrete random variable \\(DRV\\).\n\n\n\n\n\n\nTip\n\n\n\nFor a discrete random variable \\(X\\), the associate sample space \\(\\Omega\\) must countain only a countable number for real number. For example, \\(\\Omega = \\{ 1,,2,3,4,5,6 \\}\\) or \\(\\Omega = \\{ 0,1,2, \\ldots \\}\\)\n\n\nüí¨ Definition 3.6 Probability Mass Function(PMF) The PMF of a DRV is defined as \\[\nf_{X}( x ) = P( X = x ) \\\\text{for all x } \\in \\mathbb{R}\n\\]\n‚öñÔ∏è Theorem 3.6 Properties of PMF - \\(0\\le f_{X}( x ) \\le 1\\) for all \\(x \\in \\mathbb{R}\\) - \\(\\sum_{x \\in \\Omega}f_{X}( x ) = 1\\)\nüí¨ Definition 3.7 SupportThe collection of the points on the real line \\(\\mathbb{R}\\) at which a DRV \\(X\\) has a positive probability is called the support of \\(X\\),denoted as \\[\nSupport( X ) = \\{ x \\in \\mathbb{R}:f_{X}( x ) &gt; 0 \\}\n\\] Therefore,we have \\[\nSupport( X ) = \\Omega\n\\]\nWe pay attention to the point with the PMF greater than zero.\n\nThe support of \\(X\\) is the set of all possible values that \\(X\\) can take with strictly positive probability. Although \\(f_{X}( x )\\)is defined on the entire real line \\(\\mathbb{R}\\),it suffices to know the support of a DRV \\(X\\) and the probabilities of all points in the support. The PMF fx(x)can be represented graphically via a so-called probability historgram.\n\nüí¨ Definition Probability Histogram A probability histogram is a plot to represent a discrete probability distribution where rectangles are constructed so that their bases of equal width are centered at each value \\(x\\) and their heights are equal to the corresponding probabilities given by the PMF.The bases are constructed so as to have no space between the rectangles.\n\n\n\nprobability Histogram.png\n\n\n‚öñÔ∏è Theorem 3.7 Suppose \\(f_{X}( x )\\) is the PMF of the DRV \\(X\\). Then CDF of a DRV \\(X\\) \\[\nF_{X}( x ) = p( X \\le x ) = \\sum_{y \\le x}f_{X}( y ) \\text{ for any x } \\in \\mathbb{R}\n\\]\nwhere the summation is over all values \\(y\\) in \\(\\Omega\\)that are less than or equal to \\(x\\).\n\n\n\n\n\n\nImportant\n\n\n\n\n\\(F_{X}( x )\\) is defined not only in over the Support of \\(X\\), but on the whole real line.\n\n\n\nüå∞: Suppose a random variable \\(X\\) has the following PMF, \\[\nf_{X}( x ) =\n\\begin{cases} \\frac{1}{N },& x =1,2, \\ldots N  \\\\ 0, &  \\text{otherwise}\\end{cases}\n\\] Find its CDF \\(F_{X}( x )\\)\nüëâüèª: To compute the CDF \\(F_{X}( x )\\),where \\(x\\) ranges from \\(-\\infty \\text{to } +\\infty\\), we divide the real line \\(\\mathbb{R}\\) into \\(N + 1\\) intervals:\ncase 1 : \\(x &lt;1\\). Then the event \\(\\{ X \\le x \\}\\) is an empty set \\(\\emptyset\\) and \\[\nF_{X}( x ) = \\sum_{x_i \\le x}f_{X}( x_i ) = 0\n\\]\ncase 2 : \\(1 \\le x &lt; 2\\). Then the event \\(\\{ X \\le x \\} = \\{ 1 \\}\\), and so \\[\nF_{X}( x ) = \\sum_{x_i \\le x}f_{X}( x_i ) = f_{X}( 1 ) = \\frac{1}{N }\n\\]\ncase j :\\(j-1 \\le x &lt; j, 2 \\le j\\le N\\). Then the event \\(\\{ X \\le x\\} = \\{ 1, \\ldots ,j-1 \\}\\), and \\[\nF_{X}( x ) = \\frac{j-1}{N }\n\\]\ncase N+1 :\\(x\\ge N\\) Then the event \\(\\{ X\\le x \\} = \\{ 1, \\ldots ,N \\}\\), and so \\[\nF_{X}( x ) = 1\n\\]\nTo sumup, we have\n\\[\nF_{X}( x ) =\n\\begin{cases} 0, & x&lt;1 \\\\ \\frac{j}{N }, &  j \\le x &lt; j+1, 1 \\le j &lt; N \\\\ 1, & x \\ge N \\end{cases}\n\\]\n\nThis function is a step function, where jumps occur ar the points with strictly positive probabilities that is , when jumps occur at the points contained in the support of \\(X\\)\n\n‚öñÔ∏è Theorem 3.8  Suppose \\(X\\) is a DRV with CDP \\(F_{X}( x )\\), and its support contains a squence of points \\(\\{ x_1 &lt;x_2&lt;\\cdots \\}\\) Then its PMF \\[\nf_{X}( x_i ) = \\begin{cases} F_{X}( x_i ), &  i=1\\\\ F_{X}( x ) - F_{X}( x_{i-1} ), & i&lt;1  \\end{cases}\n\\]"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#continuous-random-variables",
    "href": "Random Variables and Univariate Probability Distributions.html#continuous-random-variables",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.4 Continuous Random Variables",
    "text": "3.4 Continuous Random Variables\nüí¨ Definition 3.9 Continuous Random Variable A random variable \\(X\\) is called contiuous if its distribuiton function \\(F_{X}( x )\\) is continuous for all \\(x\\) in the real line. In contrast, a random variable \\(X\\) is discrete if \\(F_{X}( x )\\) is a step funciton of \\(x\\)\n{width = ‚Äú50%‚Äù fig-align = ‚Äúcenter‚Äù}\n‚úÖ can we define a PMF \\(f_{X}( x )\\) for a CRV \\(X\\)\nFor any constant $&gt; 0 $, \\(\\{ X =x \\} \\subset \\{ x-\\frac{\\epsilon}{2 }&lt; X \\le x + \\frac{\\epsilon}{2 } \\}\\)\n\\[\n\\begin{aligned}\n0 &\\le P(X = x) \\\\\n&\\le P(x-\\frac{\\epsilon}{2 }&lt; X \\le x + \\frac{\\epsilon}{2 }) \\\\\n&= F_{x}( x+ \\frac{\\epsilon}{2 } ) - F_{X}( x - \\frac{\\epsilon}{2 } ) \\\\\n&\\to 0 \\text{ as } \\epsilon \\to 0 \\\\\n\\end{aligned}\n\\] by continuity of \\(F_{X}( \\cdot )\\) Thus \\[\nP( X=x ) = 0 \\text{for all} x\n\\]\n\nfor a CRV \\(X\\), the probability that \\(X\\) takes a single point is zero\nIntuition: consider an analogous example of a satellite flying over Mainland China.Suppose it takes one hour for the satellite to fly over Mainland,2 minutes to fly over Fujian,and 0.1 second to fly over Xiamen.It is conceivable that it takes almost zero second for the satellite to fly over Economic Building at XMU.\nThe result that \\(P(X=x)=0\\) for all \\(x\\) for a CRV \\(X\\) has important implications.For example, \\[\nP( a &lt; X \\le b) =P( a \\le X&lt; b ) \\\\\n= P(a \\le X \\le B)\n\\]\n\nüí¨ Definition Absolute Continuity(AC) A function \\(F: \\mathbb{R} \\to \\mathbb{R}\\) is called absolutely continuous with respect to the Lebesgue measure if \\(F( x )\\) is continuous on \\(\\mathbb{R}\\) and is differentiable almost everywhere\n\nWhat is meant by ‚Äúalmost everywhere‚Äù Intuitively,in any finite interval of \\(\\mathbb{R}\\),there are a finite number of points or an infinite but countable number of points where \\(F_{X}( x )\\)is not differentiable. A continuously differentiable function is absolutely continuous.\n\nüí¨ Definition 3.10 Probability Density Function(PDF) Let \\(X\\) be a CRV with absolutely continuous CDF \\(F_{X}( x )\\). If there exists a function \\(f_{X}( x )\\) such that\n\\[\nF_{X}( x ) = \\int_{-\\infty}^{x}f_{X}( y )dy \\text{ for all } x \\in \\mathbb{R}\n\\]\nThe function \\(f_{X}( x ) :\\mathbb{R} \\to \\mathbb{R}\\) is called a probability density function (PDF) of \\(X\\).\nIn other words, we have\n\\[\nF^{'}_{X}( x ) = f_{X}( x ) \\text{ for almost all } x \\in \\mathbb{R}\n\\]\nFor interpretation of the PDF \\(f_{X}( x )\\), we have,for any small constant \\(\\epsilon &gt; 0\\), \\[\n\\begin{aligned}\n&P( x-\\frac{\\epsilon}{2 }&lt;X \\le x + \\frac{\\epsilon}{2 } ) \\\\\n=& F_{X}( x + \\frac{\\epsilon}{2 } ) - F_{X}( x - \\frac{\\epsilon}{2 } ) \\\\\n=& \\int_{x-\\frac{\\epsilon}{2 }}^{x+\\frac{\\epsilon}{2 }}f_{X}( y )dy \\\\\n=& f_{X}( \\bar{x}  ) \\epsilon\n\\end{aligned}\n\\]\nfor some \\(\\bar{x } \\in (x-\\frac{\\epsilon}{2 }, x + \\frac{\\epsilon}{2 }]\\)\n\nAlthough \\(f_{X}( x )\\)is not a probability measure(i.e., the probability mass function for DRV),it is proportional to the probability that x takes values in a small interval centered at point \\(x\\) .Thus,\\(f_{X}( x )\\)characterizes the relative magnitude of the probability that \\(X\\) takes values in a small interval centered at \\(x\\).\nThe plot of \\(f_{X}( x )\\)describes the shape of the probability distribution of a CRV \\(X\\).\n\n‚ÅâÔ∏èÔ∏è Is \\(f_{X}( x )\\) a unique function for a given \\(F_{X}( x )\\)\n\nGiven a CDF \\(F_{X}( x )\\), we can obtain the PDF function \\(f_{X}( x ) = F_{X}^{'}( x )\\) at the points where \\(F_{X}( x )\\) is differentiable. When \\(F_{X}( x )\\) differentiable on the entire real line, the PDF \\(f_{X}( x )\\) is unique.\nHowever, when \\(F_{X}( x )\\) is not differentiable at some points, \\(f_{X}( X )\\) is not defined at those points.\n\n‚úÖ So how to define the values of PDF \\(f_{X}( x )\\) at the points where \\(F^{'}( x )\\) does not exit\n\nwe can define \\(f_{X}( x )\\) arbitrarily at those points, but smooth as possible for compute convenience.\nExample: consider two PDFs\n\n\\[\n\\begin{aligned}\nf_{X}( x ) = \\begin{cases} e^{-x}, & for 0 &lt;x &lt; \\infty \\\\0 , &  elsewhere\\end{cases} \\\\\n\\text{and}\\\\\nf_{X}( x ) = \\begin{cases} e^{-x}, & for 0 \\le x &lt;\\infty  \\\\ 0, & f \\end{cases}\n\\end{aligned}\n\\]\n‚öñÔ∏è Theorem 3.9 Properties of PDF A function \\(f_{X}( x )\\) is a PDF of a CRV \\(X\\) if and only if it satisfies the following properties:\n\n\\(f_{X}( x ) \\ge 0\\) for all \\(x \\in \\mathbb{R}\\)\n\\(\\int_{-\\infty}^{\\infty}f_{X}( x )dx = 1\\)\n\n‚öñÔ∏è Theorem 3.12 Support of a CRV The support of a CRV \\(X\\) is the set of all points \\(x\\) in \\(\\mathbb{R}\\) such that \\(f_{X}( x ) &gt; 0\\). That is, \\[\nsupport( X ) = \\{ x \\in \\mathbb{R}:f_{X}( x ) &gt; 0 \\}\n\\] where \\(f_{X}( x )\\) is the PDF of \\(X\\), but it is important that the \\(P(X = x) , x \\in Support(x)\\).\n\nThe support of a CRV \\(X\\) is the set of all possible points on \\(\\mathbb{R}\\) with strictly positive PDF \\(f_{X}( X )\\).\nThe probability that a CRV \\(X\\) takes values in a small neighborhood of any point in its support is always positive.\nIn contrast,the probability that X takes values in some small neighborhood of any point outside the support will be zero.\nIt suffices to focus on the support of \\(X\\) when calculating the probabilities of a CRV.\n\nüå∞: Location_Scale Family Let \\(f( x )\\) be a PDF, and let \\(\\mu\\) and \\(\\sigma&gt;0\\) be any given constants.Then the funciton\n\\[\ng( x ) = \\frac{1}{\\sigma}f( \\frac{x-\\mu}{\\sigma} )\n\\]\nis a PDF\n\nThe family of f(x-u),indexed by parameter u,is called the location family with standard PDF f(x),where pa- rameter u is called the location parameter. The family of ifÔºàÔºâ,indexed by parameter o,is called the scale family with standard PDF f(x),where param- eter o is called the scale parameter. The family of IfÔºàÔºâ,indexed by parameters (u,o), is called the location-scale family with standard PDF ,where u and o are called the location and scale parameters respectively."
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#functions-of-a-random-variable",
    "href": "Random Variables and Univariate Probability Distributions.html#functions-of-a-random-variable",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.5 Functions of a Random Variable",
    "text": "3.5 Functions of a Random Variable"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#mathematical-expectation",
    "href": "Random Variables and Univariate Probability Distributions.html#mathematical-expectation",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.6 Mathematical Expectation",
    "text": "3.6 Mathematical Expectation"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#moments",
    "href": "Random Variables and Univariate Probability Distributions.html#moments",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.7 Moments",
    "text": "3.7 Moments"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#quantiles",
    "href": "Random Variables and Univariate Probability Distributions.html#quantiles",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.8 Quantiles",
    "text": "3.8 Quantiles"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#moment-generating-function-mgf",
    "href": "Random Variables and Univariate Probability Distributions.html#moment-generating-function-mgf",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.9 Moment Generating Function (MGF)",
    "text": "3.9 Moment Generating Function (MGF)"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#characteristic-function",
    "href": "Random Variables and Univariate Probability Distributions.html#characteristic-function",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.10 Characteristic Function",
    "text": "3.10 Characteristic Function"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#conclusion",
    "href": "Random Variables and Univariate Probability Distributions.html#conclusion",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.11 Conclusion",
    "text": "3.11 Conclusion"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#condition-2",
    "href": "Random Variables and Univariate Probability Distributions.html#condition-2",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.2 Condition ( 2 )",
    "text": "3.2 Condition ( 2 )\n\\[\nP_{X}( \\Omega ) = P( S ) = 1\n\\]"
  },
  {
    "objectID": "Random Variables and Univariate Probability Distributions.html#condition-3",
    "href": "Random Variables and Univariate Probability Distributions.html#condition-3",
    "title": "3¬† Random Variables and Univariate Probability Distributions",
    "section": "3.3 Condition ( 3 )",
    "text": "3.3 Condition ( 3 )\nconsider two mutually exclusive events \\(A_1\\) and \\(A_2\\) in \\(\\mathbb{B}_{\\Omega}\\), a \\(\\sigma\\)-field generated from \\(\\Omega\\). Here, the induced probability of \\(A_1 \\cap A_2\\) is given by \\[\nP_{X}( A_1 \\cap  A_2 ) = P( C )\n\\]\nwhere \\(C = \\{ s\\in S: X( s ) \\in A_1 \\cap A_2 \\}\\)\nHowever, we can also write \\[\nC = \\{ s \\in S : X( s ) \\in A_1 \\} \\cap \\{ s \\in S : X( s ) \\in A_2 \\} \\\\\n= C_1 \\cap C_2\n\\]\nThe fact that \\(A_1\\) and \\(A_2\\) are disjoint implies that \\(C_1\\) and \\(C_2\\) are also disjoint. It follows that\n\\[\nP_{x}( A_1 \\cap A_2  ) = P( C_1 ) + P( C_2 ) \\\\\n= P_{x}( A_1 ) + P_{X}( A_2 )\n\\]"
  }
]