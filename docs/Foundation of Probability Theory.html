<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Probability Theory - 2&nbsp; Foundation of Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Foundation of Probability Theory.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Foundation of Probability Theory</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Probability Theory</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/Zeuyel/Probability_Book_Hong" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduce</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Foundation of Probability Theory.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Foundation of Probability Theory</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#random-experiments" id="toc-random-experiments" class="nav-link active" data-scroll-target="#random-experiments"><span class="header-section-number">2.1</span> Random Experiments</a></li>
  <li><a href="#basic-concepts-of-probability" id="toc-basic-concepts-of-probability" class="nav-link" data-scroll-target="#basic-concepts-of-probability"><span class="header-section-number">2.2</span> Basic Concepts of Probability</a></li>
  <li><a href="#review-of-set-theory" id="toc-review-of-set-theory" class="nav-link" data-scroll-target="#review-of-set-theory"><span class="header-section-number">2.3</span> Review of Set Theory</a></li>
  <li><a href="#fundamental-probability-laws" id="toc-fundamental-probability-laws" class="nav-link" data-scroll-target="#fundamental-probability-laws"><span class="header-section-number">2.4</span> Fundamental Probability Laws</a>
  <ul class="collapse">
  <li><a href="#approach-1relative-frequency-interpretation" id="toc-approach-1relative-frequency-interpretation" class="nav-link" data-scroll-target="#approach-1relative-frequency-interpretation"><span class="header-section-number">2.4.1</span> Approach 1:Relative frequency interpretation</a></li>
  <li><a href="#approach-2subjective-probability-interpretation" id="toc-approach-2subjective-probability-interpretation" class="nav-link" data-scroll-target="#approach-2subjective-probability-interpretation"><span class="header-section-number">2.4.2</span> Approach 2:Subjective Probability interpretation</a></li>
  </ul></li>
  <li><a href="#methods-of-counting" id="toc-methods-of-counting" class="nav-link" data-scroll-target="#methods-of-counting"><span class="header-section-number">2.5</span> Methods of Counting</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability"><span class="header-section-number">2.6</span> Conditional Probability</a></li>
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem"><span class="header-section-number">2.7</span> Bayes‚Äô Theorem</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="header-section-number">2.8</span> Independence</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">2.9</span> Conclusion</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Zeuyel/Probability_Book_Hong/edit/main/Foundation of Probability Theory.md" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Foundation of Probability Theory</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="random-experiments" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="random-experiments"><span class="header-section-number">2.1</span> Random Experiments</h2>
<p><strong>[üí¨ Definition 1. Random Experiment]</strong> A random experiment is an experiment whose outcome is not known in advance.</p>
<p>there are two essential elements of a random experiment:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>the set of all possible outcomes</p>
<p>the likelihood of each outcome</p>
</div>
</div>
<p>we need to know the sample space and the probability of each outcome in the sample space.</p>
<p>‚óè The purpose of mathematical statistics is to provide mathematical models for random experiments ofinterest.<br>
‚óè Once a model for such an experiment is provided and the theory worked out in detail, the statistician may,within this framework, make inference about the probability law of the random experiment.</p>
</section>
<section id="basic-concepts-of-probability" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="basic-concepts-of-probability"><span class="header-section-number">2.2</span> Basic Concepts of Probability</h2>
<p><strong>[üí¨ Definition 2. Sample Space]</strong> The possible outconmes of a random experiment are called the sample space and is denoted by <span class="math inline">\(S\)</span>.</p>
<p>When an experiment is performed, the realization of the experiment will be one <strong>(and only one)</strong> outcome in thesample space.(Mutually exclusive)</p>
<p>If the experiment is performed a number of times, a different outcome may occur each time or some outcomes may repeat.</p>
<p>a sample space <span class="math inline">\(S\)</span> can be countable or uncountable.</p>
<p><strong>[üí¨ Definition 3. Event]</strong> An event <span class="math inline">\(A\)</span> is a collection of basic outcomes from the sample space S that share certain common features or equivalently obey certain restrictions.</p>
<p>The event is the <strong>subset</strong> of the sample space.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><span class="math inline">\(Basic outconme \subseteq Event \subseteq Sample\ space\)</span></li>
</ul>
</div>
</div>
</section>
<section id="review-of-set-theory" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="review-of-set-theory"><span class="header-section-number">2.3</span> Review of Set Theory</h2>
<p>‚úÖUse Venn Diagram to represent the relationship between sets(or sample point,event, all the related concepts).</p>
<p><strong>[üí¨ Definition 4. Intersection]</strong> Intersection of <span class="math inline">\(A\)</span> and B, denoted <span class="math inline">\(A \cap B\)</span>Ôºå is the set of basic outcomes in S that belong to both <span class="math inline">\(A\)</span> and B.The intersection of <span class="math inline">\(A\)</span> and B is the event that both <span class="math inline">\(A\)</span> and B occur. is also called the <strong>logicall product</strong> of <span class="math inline">\(A\)</span> and B.</p>
<p><strong>[üí¨ Definition 5. Exclusiveness]</strong> If <span class="math inline">\(A\)</span> and B have no common basic outcomes, they are called mutually exclusive and their intersection is empty set <span class="math inline">\(\emptyset\)</span>, i.e., <span class="math inline">\(A \cap B = \emptyset\)</span> where <span class="math inline">\(\emptyset\)</span> denotes an empty set that contains nothing.</p>
<ul>
<li>mutually exclusive events are also called disjoint events.</li>
</ul>
<p><strong>[üí¨ Definition 6. Union]</strong> The union of <span class="math inline">\(A\)</span> and B, denoted <span class="math inline">\(A \cup B\)</span>, is the set of basic outcomes in S that belong to either A or B or both. The union of A and B is the event that either A or B or both occur. is also called the <strong>logical sum</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>.</p>
<p><strong>[üí¨ Definition 7. Collective Exhaustiveness]</strong> Suppose that <span class="math inline">\(A_1, A_2, A_3, \cdots\)</span> are events in S. If <span class="math inline">\(A_1 \cup A_2 \cup A_3 \cup \cdots = S\)</span>, then the events <span class="math inline">\(A_1, A_2, A_3, \cdots\)</span> are collectively exhaustive.</p>
<p><strong>[üí¨ Definition 8. Complement]</strong> The complement of A, denoted <span class="math inline">\(A^c\)</span>, is the set of basic outcomes in S that do not belong to A. The complement of A is the event that A does not occur.</p>
<ul>
<li><span class="math inline">\(A \cap A^{c} = \emptyset \ and \ A \cup A^{c} = S\)</span></li>
</ul>
<p><strong>[üí¨ Definition 9. Difference]</strong> The difference of A and B, denoted <span class="math inline">\(A - B = A \cap B^{c}\)</span>, is the set of basic outcomes in S that belong to A but not to B. The difference of A and B is the event that A occurs but B does not occur.</p>
<p>üßÆDistributivity Laws :</p>
<p><span class="math display">\[
A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\\
A \cup (B \cap C) = (A \cup B) \cap (A \cup C)
\]</span></p>
<p>In more general, we have <span class="math display">\[
B \cap \left( \bigcup_{i=1}^{n} A_i \right)= \bigcup_{i=1}^{n} (B \cap A_i) \\
B \cup \left( \bigcap_{i=1}^{n} A_i \right)= \bigcap_{i=1}^{n} (B \cup A_i)
\]</span></p>
<p>üßÆ De Morgan‚Äôs Laws</p>
<p><span class="math display">\[
\left( A \cup  B \right)^{c} =A^{c} \cap B^{c}
\left( A \cap  B  \right)^{c} = A^{c} \cup B^{c}
\]</span></p>
<p>In more general, we have <span class="math display">\[
\left( \bigcup_{i=1}^{n} A_i \right)^{c} = \bigcap_{i=1}^{n} A_i^{c} \\
\left( \bigcap_{i=1}^{n} A_i \right)^{c} = \bigcup_{i=1}^{n} A_i^{c}
\]</span></p>
<hr>
<p>üå∞: Suppose the events A and B are disjoint.Under what condition are <span class="math inline">\(A^{c}\)</span> and <span class="math inline">\(B^{c}\)</span> also disjoint?</p>
<p>üëâ: <span class="math inline">\(A^{c}\)</span> and <span class="math inline">\(B^{c}\)</span> are disjoint if and only if <span class="math inline">\(A \cup B = S\)</span>.That is say <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is exhaustive.</p>
<p>üå∞: ‚Ä¢ Are <span class="math inline">\(A \cap B\)</span> and <span class="math inline">\(A^{c} \cap B\)</span> mutually exclusive?</p>
<p>‚Ä¢ Is <span class="math inline">\(\left( A \cap B \right) \cup \left( A^{c} \cap B \right) = B\)</span>?</p>
<p>‚Ä¢ Are <span class="math inline">\(A\)</span> and <span class="math inline">\(A^{c} \cap B\)</span> mutually exclusive?</p>
<p>‚Ä¢ Is <span class="math inline">\(A \cup \left( A^{c} \cap B \right) = A \cap B\)</span>?</p>
<p>üëâÔºöYes, Yes, Yes, No</p>
<p>üå∞: Let the set of events <span class="math inline">\(\{ A_i = 1 , \ldots ,n \}\)</span> be mutually exclusive and collectively exhaustive, and let A be an event in S - Are <span class="math inline">\(A_1 \cap A, \ldots ,A_n \cap A\)</span> mutually exclusive? - Is the union of <span class="math inline">\(A_i \cap A, i = 1, \ldots ,n\)</span>, equal to A? That is, do we have: <span class="math display">\[
\bigcup_{i=1}^{n} \left( A_i \cap A \right) = A
\]</span></p>
<p>üëâ: Yes, Yes</p>
<blockquote class="blockquote">
<p>In the linear algebra, we can use the projection matrix to understand this.The <span class="math inline">\(\{ A_1,A_2, \ldots ,A_n \}\)</span> is the orthogonal bases of the specific space, and the <span class="math inline">\(A\)</span> is the vector in this space. The <span class="math inline">\(A_i \cap A\)</span> is the projection of <span class="math inline">\(A\)</span> on the <span class="math inline">\(A_i\)</span> direction.</p>
<ul>
<li><p>A sequence of collective and mutually exclusive events forms a partition of sample space S.</p></li>
<li><p>A set of collectively exhaustive and mutually exclusive events can be viewed as a complete set of orthogonal bases.</p></li>
<li><p>The projection of a vector on a subspace is the sum of the projections of the vector on the orthogonal bases of the subspace.</p></li>
<li><p>A complete set of orthogonal bases can represent any event A in the sample space S, and ùê¥ùëñ ‚à© ùê¥ could be viewed as the projection of event A on the base <span class="math inline">\(A_i\)</span>.</p></li>
</ul>
</blockquote>
<hr>
</section>
<section id="fundamental-probability-laws" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="fundamental-probability-laws"><span class="header-section-number">2.4</span> Fundamental Probability Laws</h2>
<p>‚úÖ To assign a probability to an event <span class="math inline">\(A \in S\)</span>, we shall introduce a <strong>probability function</strong>, which is a function or a mapping from an event to a real number (0,1).</p>
<p>‚úÖ To assign probabilities to events, complements of events,unions and intersections of events, we want our collection of events to include all these combinations of events.</p>
<p>‚úÖSuch a collection of events is called an <span class="math inline">\(\sigma\)</span>-field(<span class="math inline">\(\sigma\)</span> algaebra) of subsets of the sample space S,which constitude the domain of the probability function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img10.360buyimg.com/ddimg/jfs/t1/209581/28/38739/6451/656b139eF3f92090d/e8ba1188e7d747ec.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<p><strong>[üí¨ Definition 10. Sigma Algebra]</strong> A <span class="math inline">\(sigma(\sigma) algebra\)</span>,denoted by <span class="math inline">\(\mathbb{B}\)</span> , is a collection of subsets(events) of S that satisfies the following three conditions:</p>
<ol type="1">
<li><span class="math inline">\(\emptyset \in \mathbb{B}\)</span>i.e., the empty set is in <span class="math inline">\(\mathbb{B}\)</span>.</li>
<li>If <span class="math inline">\(A \in \mathbb{B}\)</span>, then <span class="math inline">\(A^{c} \in \mathbb{B}\)</span>.(i.e., <span class="math inline">\(\mathbb{B}\)</span> is closed under complements)</li>
<li>If <span class="math inline">\(A_1,A_2, \ldots \in \mathbb{B}\)</span>, then <span class="math inline">\(\bigcup_{i=1}^{\infty} A_i \in \mathbb{B}\)</span>.(i.e., <span class="math inline">\(\mathbb{B}\)</span> is closed under countable unions)</li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><span class="math inline">\(\sigma\)</span>-algebra is a collection of events in <span class="math inline">\(S\)</span>(subset) that satisfies certain properties and constitutes the domain of a probability function.</li>
<li>A <span class="math inline">\(\sigma\)</span> -field is a collection of subsets in <span class="math inline">\(S\)</span> , but itself is not a subset of <span class="math inline">\(S\)</span> . In contrast, the sample space <span class="math inline">\(S\)</span> is <strong>only an element of a</strong> <span class="math inline">\(\sigma\)</span> -field.</li>
<li>The pair <span class="math inline">\((S,\mathbb{B})\)</span> is called a measurable space.So for a specific sample space <span class="math inline">\(S\)</span>, we can have different <span class="math inline">\(\sigma\)</span>-algebra <span class="math inline">\(\mathbb{B}\)</span>.</li>
</ul>
</div>
</div>
<p><strong>[üí¨ Definition 11. Probability Function]</strong> Suppose a random experiment has a sample space <span class="math inline">\(S\)</span> and an associated <span class="math inline">\(\sigma\)</span> -field <span class="math inline">\(\mathbb{B}\)</span> . A probability function <span class="math display">\[
P:\mathbb{B} \to [0,1]
\]</span></p>
<p>is defined as a mapping that satisfies the following three conditions:</p>
<ol type="1">
<li><p><span class="math inline">\(0 \le P(A) \le 1 for all A \in \mathbb{B}\)</span> .</p></li>
<li><p><span class="math inline">\(P(S) = 1\)</span>.</p></li>
<li><p>If <span class="math inline">\(A_1,A_2, \ldots \in \mathbb{B}\)</span> are mutually exclusive, then <span class="math inline">\(P\left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P(A_i)\)</span>.üö©The probability of the union of mutually exclusive events is the sum of the probabilities of the individual events.</p></li>
</ol>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>A probability function tell how the probability of occurrence is distributed over the set of events <span class="math inline">\(\mathbb{B}\)</span>.In this sense we speak of a distribution of probability.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img12.360buyimg.com/ddimg/jfs/t1/232346/23/5558/25512/656c2680F5d41484e/4bbc3248c4c4ad99.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<ul>
<li>For a given measurable space <span class="math inline">\((S,\mathbb{B})\)</span>, many different probability functions can be defined. The goal of econometrics and statistics is to find a probability function that <strong>most accurately describes the underlying DGP</strong>. This probability function is usually called the <strong>true probability function</strong> or true probability distribution model.</li>
</ul>
</div>
</div>
<p>‚úÖSo how to interpret the probability target to an event?</p>
<section id="approach-1relative-frequency-interpretation" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="approach-1relative-frequency-interpretation"><span class="header-section-number">2.4.1</span> Approach 1:Relative frequency interpretation</h3>
<p>The probability of an event can be viewed as the limit of the ‚Äù relative frequency‚Äù of occurrence of the event in a large number of repeated independent experiments under essentially the same conditions.</p>
<p>The relative frequency interpretation is valid under the assumption of a large number of repeated experiments under the same condition. In statistics, such an assumption is formally termed as <strong>‚Äúindependence and identical distribution (IID)‚Äù</strong>.</p>
<blockquote class="blockquote">
<p>‚ÅâÔ∏è When the weather forecast bureau predicts that there is a 30% chance for raining, it means that under the same weather conditions it will rain 30% of the times. We cannot guarantee what will happen on any particular occasion, but if we keep records over a long period of time, we should find that the proportion of ‚Äúraining‚Äù is very close to 0.30 for the days with the same weather condition.</p>
<p>But in practical applications, we cannot repeat the same experiment a large number of times under the same conditions. Therefore, the relative frequency interpretation is not very useful in practice. We introduce the <strong>subjective interpretation</strong> of probability.</p>
</blockquote>
</section>
<section id="approach-2subjective-probability-interpretation" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="approach-2subjective-probability-interpretation"><span class="header-section-number">2.4.2</span> Approach 2:Subjective Probability interpretation</h3>
<p>The subjective method views probability as a <strong>belief</strong> in the chance of an event occurring.But a personal or subjective assessment is made of theprobability of an event which is difficult or impossible to estimate in any way.So is that means the subjective probability is not useful?</p>
<p>üå∞: Subjective probability is the foundation of Bayesian statistics, which is a rival to classical statistics.</p>
<p>üå∞: Rational Expectations</p>
<p>Rational expectations (Muth 1961) hypothesizes that the <strong>subjective expectation</strong> of an economic agent (i.e., the expectation under the subjective probability belief of the economic agent) <strong>coincides with the mathematical expectation</strong> (i.e., the expectation under the objective probability distribution).</p>
<p>For example, we eager to have a wage <span class="math inline">\(S\)</span>, but we don‚Äôt know the exact value of <span class="math inline">\(S\)</span>. We can only estimate the probability distribution of <span class="math inline">\(S\)</span> based on our subjective probability belief. The rational expectation hypothesis states that the subjective expectation of <span class="math inline">\(S\)</span> is equal to the mathematical expectation of wage :the <span class="math inline">\(E(S)\)</span>.</p>
<p>üå∞: Professional Forecast</p>
<p>The U.S. central bank‚ÄîFed issues professional forecasts for important macroeconomic indicators such as GDP growth rate, inflation rate and unemployment rate.</p>
<p>In each quarter, they send surveys to professional forecasters, asking their views on probability distributions of these important macroeconomic indicators.</p>
<p>Specifically, each forecaster will be asked what is his/her forecast of the probability that the inflation rate lies in various intervals.</p>
<p>üå∞: Risk Neutral Probability</p>
<p>During the 1997-1998 Asian financial crisis, many investors were very concerned with the collapse of the Hong Kong peg exchange rate system with U.S. dollars and devaluations of Hong Kong dollars.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img11.360buyimg.com/ddimg/jfs/t1/228856/24/5468/42874/656c39c7Fd1972412/7bdaf3e6562136fd.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>In other words, their subjective probabilities of Hong Kong dollar devaluation were higher than the objective probabilities of the Hong Kong dollar movements. The former are called risk-neutral probability distributions and the latter are called objective or physical probability distributions in finance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img14.360buyimg.com/ddimg/jfs/t1/236374/40/5377/11113/656c3a44Fd120b79c/6d287fddf41db3f9.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>The gap between these two distributions reflects the risk attitude of market investors. The risk-neutral probability distribution is a financial instrument in derivative pricing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img10.360buyimg.com/ddimg/jfs/t1/236100/21/5419/27681/656c3ef3Fced1a70c/8ec3cf9e73ffb875.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p><strong>[üí¨ Definition 12. Probability Space]</strong> A probability space is a triple <span class="math inline">\((S,\mathbb{B},P)\)</span>, where <span class="math inline">\(S\)</span> is a sample space, <span class="math inline">\(\mathbb{B}\)</span> is a <span class="math inline">\(\sigma\)</span>-field of subsets of <span class="math inline">\(S\)</span>, and <span class="math inline">\(P:\mathbb{b} \to [0,1]\)</span> is a probability function defined on <span class="math inline">\(\mathbb{B}\)</span>.</p>
<blockquote class="blockquote">
<p>Because the probability function <span class="math inline">\(P(\cdot )\)</span> is defined on <span class="math inline">\(\mathbb{B}\)</span>, the collection of sets (i.e., events), it is also called a set function.</p>
</blockquote>
<p><strong>‚öñÔ∏è Theorem 1</strong> If <span class="math inline">\(\emptyset\)</span> denotes the empty set, then <span class="math inline">\(P(\emptyset) = 0\)</span>.</p>
<p>üìë Proof: Given that ùëÜ = ùëÜ ‚à™ ‚àÖ, and ùëÜ and ‚àÖ are mutually exclusive, we have <span class="math inline">\(P(S) = P(S \cup \emptyset) = P(S) + P(\emptyset)\)</span>.It follows that <span class="math inline">\(P(\emptyset) = 0\)</span>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
P(A) = 0 \text{**does not**} \Rightarrow A = \emptyset
\]</span></p>
</div>
</div>
<p><strong>‚öñÔ∏è Theorem 3</strong> <span class="math inline">\(P(A) = 1 - P(A)^{c}\)</span></p>
<p>üìë Proof: Oberve <span class="math inline">\(A \cup A^{c} = S\)</span>. Then <span class="math display">\[
P(S) = P(A \cup A^{c}) = P(A) + P(A^{c})
\]</span> Because <span class="math inline">\(P(S)=1\)</span>,<span class="math inline">\(A \text{and} A^{c}\)</span> are mutually exclusive, we have <span class="math inline">\(P(A) = 1 - P(A^{c})\)</span>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The ratio of the probability of an event <span class="math inline">\(A\)</span> to the probability of its complement, <span class="math display">\[
\frac{P(S)}{P(A^{c}) }  =\frac{P(A)}{1- P(A)}
\]</span> is called the <strong>ratio odds</strong> of <span class="math inline">\(A\)</span>.</p>
</div>
</div>
<p><strong>‚öñÔ∏è Theorem 4</strong> If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are two events in <span class="math inline">\(\mathbb{B}\)</span>, and <span class="math inline">\(A \subseteq B\)</span>, then <span class="math display">\[
P(A) \le P(B)
\]</span></p>
<p><strong>‚öñÔ∏è Theorem 5</strong> For any two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> in <span class="math inline">\(\mathbb{B}\)</span>, <span class="math display">\[
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\]</span> Keep in mind that the probability of an event is equal to the area it occupies in the sample space.</p>
<p>Since <span class="math inline">\(A \cap B \subseteq S\)</span>, we have <span class="math inline">\(P(A \cap B) \le P(S) = 1\)</span> by Theorem 4. It follows from the theorem 5 that</p>
<p><span class="math display">\[
P(A \cup B) = P(A) + P(B) - P(A \cap B) \ge P(A) + P(B) - 1
\]</span></p>
<p>It also called the <strong>Bonferroni‚Äôs inequality</strong>.</p>
<p><strong>‚öñÔ∏èÔ∏è Theorem 6 [Rule of total probability]</strong> If <span class="math inline">\(A_1,A_2, \ldots \in \mathbb{B}\)</span> are mutually exclusive and collectively exhaustive, and A is an event in <span class="math inline">\(S\)</span>, then <span class="math display">\[
P(A) = \sum_{i=1}^{\infty} P(A \cup A_i)
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://img13.360buyimg.com/ddimg/jfs/t1/232051/6/5770/25277/656c6018F97a717a5/e76558484123985a.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>So if <span class="math display">\[
A = \{ \text{students whose scores &gt; 90 points} \},\\
A_i = \{ \text{students from country i} \}
\]</span></p>
<p>then <span class="math inline">\(A \cap A_i = \{ \text{students from country i whose scores are &gt; 90 points} \}\)</span></p>
<p><strong>‚öñÔ∏è Theorem 7 [Subadditivity:Boole‚Äôinequality]</strong> For any sequence of events <span class="math inline">\(\{ A_i \in \mathbb{B}, i =1,2, \ldots \}\)</span>, <span class="math display">\[
P \left(  \bigcup_{i=1}^{\infty}A_i  \right)  \le \sum_{i=1}^{\infty} P(A_i)
\]</span></p>
</section>
</section>
<section id="methods-of-counting" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="methods-of-counting"><span class="header-section-number">2.5</span> Methods of Counting</h2>
<p>‚úÖHow to calculate the probability of event A?</p>
<p>Suppose event <span class="math inline">\(A\)</span> includes <span class="math inline">\(k\)</span> basic outcomes in the sample space <span class="math inline">\(S\)</span>. Then the probability of <span class="math inline">\(A\)</span> is given by <span class="math display">\[
P(A) = \sum_{i=1}^{k}P(A_i)
\]</span></p>
<p>If in addition <span class="math inline">\(S\)</span> consists of <span class="math inline">\(n\)</span> equally likely basic outcomes <span class="math inline">\(\{ A_1, \ldots ,A_n\}\)</span>, and event <span class="math inline">\(A\)</span> consists of <span class="math inline">\(k\)</span> basic outcomes, then</p>
</section>
<section id="conditional-probability" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="conditional-probability"><span class="header-section-number">2.6</span> Conditional Probability</h2>
</section>
<section id="bayes-theorem" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="bayes-theorem"><span class="header-section-number">2.7</span> Bayes‚Äô Theorem</h2>
<p>‚úÖ The knowledge that an event B has occurred can be used to revise or update the prior probability that an event A will occur.</p>
<p>‚úÖ Bayes‚Äô theorem describes the mechanism of revising or updating the prior probability <strong>learning</strong>.</p>
<p>‚úÖ This theorem leads to the Bayesian school of statistics, a rival to the school of classical statistics.</p>
<p><strong>‚öñÔ∏è Theorem 11 [Baye‚Äôs Theorem]</strong> Suppose A and B are two events with <span class="math inline">\(P(A) &gt; 0\)</span> and <span class="math inline">\(P(B) &gt; 0\)</span>. Then <span class="math display">\[
P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^{c})P(A^{c}) }
\]</span></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(P(A)\)</span> is called a ‚Äù prior‚Äù probability (i.e., before the fact or evidence) about event A since it is the probability of A before new information B arrives.</p>
<p>The conditional probability <span class="math inline">\(P(A|B)\)</span> is called a ‚Äúposterior‚Äù probability (i.e., after the fact or evidence) since it represents the revised assignment of probability of A after the new information that B has occurred is obtained.</p>
</div>
</div>
<p><strong>‚öñÔ∏è Theorem 12 [Alternative Statement of Bayes‚Äô Theorem] </strong> Suppose <span class="math inline">\(A_1, \ldots ,A_n\)</span> are <span class="math inline">\(n\)</span> mutually exclusive and collectively exhaustive events in the sample space <span class="math inline">\(S\)</span>, and <span class="math inline">\(A\)</span> is an event with <span class="math inline">\(P(A) &gt; 0\)</span>. Then the conditional probability of <span class="math inline">\(A_i\)</span> given <span class="math inline">\(A\)</span> is <span class="math display">\[
P(A_i|A) = \frac{P(A|A_i)P(A_i)}{\sum_{j=1}^{n}P(A|A_i)P(A_i) }, \quad i = 1,2, \ldots ,n
\]</span></p>
<p>üå∞: How to Determine Auto-insurance Premium?</p>
<p>Suppose an insurance company has three types of customers‚Äîhigh risk, medium risk and low risk. From the company‚Äôs historical consumer database, it is known that 25% of its customers are high risk, 25% are medium risk, and 50% are low risk. Also, the database shows that the probability that a customer has at least one speeding ticket in one year is 0.25 for high risk, 0.16 for medium risk, and 0.10 for low risk.</p>
<p>Now suppose a new customer wants to be insured and reports that he has had one speeding ticket this year. What is the probability that he is a high risk customer, given that he has had one speeding ticket this year?</p>
</section>
<section id="independence" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="independence"><span class="header-section-number">2.8</span> Independence</h2>
<p><strong>[üí¨ Definition 13. Independence]</strong> Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
difference between mutally exclusive and independence
</div>
</div>
<div class="callout-body-container callout-body">
<p>mutually exclusive means the <span class="math inline">\(P(A\cap b) \equiv 0\)</span> , the occrance of event <span class="math inline">\(A\)</span> means the disappear of event <span class="math inline">\(B\)</span> , but the independence means <span class="math inline">\(P(A\cap b) \equiv P(A)P(B)\)</span>.Independence is a probability notion to describe <strong>nonexistence</strong> of any kind of relationship between two events. It plays a fundamental role in probability theory and statistics. <strong>But two independent event may occur at the same time.</strong></p>
<p><img src="https://img11.360buyimg.com/ddimg/jfs/t1/228525/18/6306/11364/656f1774Ff105e0d3/476461da30ba5609.jpg" class="img-fluid"></p>
</div>
</div>
<p>Suppose <span class="math inline">\(P(B)&gt;0\)</span>.They by definition of independence:<br>
<span class="math display">\[
P(A|B) = P(A \cap B)
= \frac{P(A)P(B)}{P(B) }
= P(A)
\]</span></p>
<p>this formula shows that the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> equal to the unconditional probability of <span class="math inline">\(A\)</span>.<strong>The knowledge of <span class="math inline">\(B\)</span> does not help in predicting <span class="math inline">\(A\)</span></strong>.Similarly, we have <span class="math inline">\(P(B|A) = P(B)\)</span>, i.e.&nbsp;the occurrence of <span class="math inline">\(A\)</span> has no effect on the occurrence or probability of <span class="math inline">\(B\)</span>.Intuitively, independence implies that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>‚Äúirrelevant‚Äù</strong>, or there exists no relationship between them.</p>
<p>üå∞:Random Walk hypothesis(Fama 1970) A stock Price <span class="math inline">\(P_t\)</span> will follow a random walk if <span class="math display">\[
P_t = P_{t-1} + X_t
\]</span></p>
<p>where the <span class="math inline">\(\{ X_t \}\)</span> is the independent across different time period.</p>
<blockquote class="blockquote">
<p>Note that here the <span class="math inline">\(X_t = P_t - P_{t-1}\)</span> is the stock price change from the <span class="math inline">\(t-1\)</span> to time <span class="math inline">\(t\)</span></p>
</blockquote>
<p>Now we have a closely related concept : the geometric random walk.The stock price <span class="math inline">\(\{ P_t \}\)</span> is called a geoemtric random walk if <span class="math display">\[
\ln P_t = \ln P_{t-1} + X_t
\]</span></p>
<p><span class="math inline">\(\{ X_t \}\)</span> is independent across different time period.</p>
<p>The increment of the geometric random walk is <span class="math display">\[
X_t = \ln (\frac{P_t}{P_{t-1} })
= \ln (1 + \frac{P_t - P_{t-1} }{P_{t-1} })
\simeq \frac{P_t - P_{t-1}}{P_{t-1}}
\]</span></p>
<p>can be interpreted as the <strong>relative stock price change</strong>.In long term time series analysis, the geometric random walk is more popular than the random walk because the relative stock price change is more stable than the absolute stock price change.</p>
<p><strong>‚öñÔ∏è Theorem 13 </strong> Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are two independent events. Then</p>
<ul>
<li><span class="math inline">\(A\)</span> and Bc are independent</li>
<li><span class="math inline">\(A^{c}\)</span> and <span class="math inline">\(B\)</span> are independent</li>
<li><span class="math inline">\(A^{c}\)</span> and <span class="math inline">\(B^{c}\)</span> are independent</li>
</ul>
<p><strong>[üí¨ Definition 15 Independence Among Several Events]</strong> <span class="math inline">\(k\)</span> events <span class="math inline">\(A_1,A_2, \ldots ,A_n\)</span> are mutually independent if, for every possible subset <span class="math inline">\(A_{i_1}, \ldots ,A_{i_j}\)</span> of <span class="math inline">\(j\)</span> of those events <span class="math inline">\((j =2,3, \ldots ,k)\)</span>, <span class="math display">\[
P(A_{i_1} \cap \cdots \cap A_{i_j}) = P(A_{i_1}) \times \cdots \times P(A_{i_j})
\]</span></p>
<blockquote class="blockquote">
<p>For three or more events, independence is called mutual independence or joint independence. If there is no possibility of misunderstanding, independence is often used without the modifier ‚Äúmutual‚Äù or ‚Äújoint‚Äù when considering several events. <img src="https://img14.360buyimg.com/ddimg/jfs/t1/228636/1/6015/17059/656f2a9fF57f59405/e60c06da9f8c160d.jpg" class="img-fluid"></p>
</blockquote>
<p>üå∞: Three events <span class="math inline">\(A,B\)</span>and <span class="math inline">\(C\)</span> are independent, if the following <span class="math inline">\(2^{3} - (1+3) = 4\)</span> conditions are satisfied (<span class="math inline">\(1 \text{means the } \emptyset \text{ and the} 3 \text{means the single element set}\)</span>):</p>
<ul>
<li><span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></li>
<li><span class="math inline">\(P(A \cap B) = P(A)P(C)\)</span></li>
<li><span class="math inline">\(P(B \cap C) = P(B)P(C)\)</span></li>
<li><span class="math inline">\(P(A \cap B \cap C ) = P(A)P(B)P(C)\)</span></li>
</ul>
<p>üå∞: Complementarity Between Economic Reforms</p>
<p>In the fields of economic growth and development, many studies find that one economic policy usually necessities another policy to stimulate the economic growth, which is called policy complementarities. In traditional economics, individual reforms or sequential reforms may not be effective or fully effective, or even back-ring. Reforms must be packed together in order to be effective. Foundation of Probability Theory Independence</p>
<p>For example, in order to improve firm productivity (<span class="math inline">\(A_1\)</span>), changing a manager (<span class="math inline">\(A_2\)</span>) should be together with granting autonomy to the firm (<span class="math inline">\(A_3\)</span>).</p>
<blockquote class="blockquote">
<p>There are many other examples of economic complementarities. Harrison (1996), Ro-driguez and Rodrik (2000), Loayza et al.&nbsp;(2005), Chang et al.&nbsp;(2005) document that international trade openness, only when combined with other policies that improve a country‚Äôs educational investment, financial depth, inflation stabilization, public infrastructure, governance, labor market flexibility, and ease of firm entry and exit, can promote economic growth.</p>
</blockquote>
</section>
<section id="conclusion" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">2.9</span> Conclusion</h2>
<p>‚úÖ This chapter is a foundation of probability theory.</p>
<p>‚úÖ We first characterize a random experiment by a probability space <span class="math inline">\((S, \mathbb{B}, P)\)</span>. Interpretations for probabilities are provided.To the probability function, we need to estimate it from data to get a <strong>true probability function</strong></p>
<p>‚úÖ Given a measurable space <span class="math inline">\((ùëÜ, ùîπ)\)</span>, one can dene many probability functions. The main objective of econometrics is to use the observed economic data to infer a suitable probability function which truly represents the true probability distribution for the data generating process.</p>
<p>‚úÖ For random experiments with equally likely outcomes, methods of counting are very useful in calculating probabilities of interested events.</p>
<p>‚úÖ The conditional probability function characterizes predictive relationships between or among economic events. An application is Bayes‚Äô theorem.</p>
<p>‚úÖ Finally, we introduce the concept of independence and its implications in economics and finance.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduce</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>